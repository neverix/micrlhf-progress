{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "!sudo rm /tmp/libtpu_lockfile\n",
    "import penzai\n",
    "from penzai import pz\n",
    "import jax.numpy as jnp\n",
    "import jax_smi\n",
    "import jax\n",
    "jax_smi.initialise_tracking()\n",
    "pz.ts.register_as_default()\n",
    "pz.ts.register_autovisualize_magic()\n",
    "pz.enable_interactive_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 64\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folding and caching...\n"
     ]
    }
   ],
   "source": [
    "from micrlhf.llama import LlamaTransformer\n",
    "from micrlhf.caching_llama import FoldedLlamaKVCachingTransformer\n",
    "from micrlhf.flash import flashify\n",
    "\n",
    "llama = LlamaTransformer.from_pretrained((\"models/llama-3-70b-1.gguf\", \"models/llama-3-70b-2.gguf\"),\n",
    "                                         device_map=\"auto:mp=4\", load_on_cpu=True,\n",
    "                                        #  transpose_rotary=False\n",
    "                                        #  transpose_rotary=True\n",
    "                                         )\n",
    "print(\"Folding and caching...\")\n",
    "llama, cache = FoldedLlamaKVCachingTransformer.from_uncached(llama, max_seq_len, {\"batch\": batch_size})\n",
    "# llama = flashify(llama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama = llama.to_tpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neverix/.cache/pypoetry/virtualenvs/micrlhf-progress-a058ydGG-py3.12/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nvidia/Llama3-ChatQA-1.5-70B\")\n",
    "prompt = tokenizer.apply_chat_template([\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "], tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c27a01c0c6e46e890c7638187109729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Custom node type mismatch: expected type: <class 'micrlhf.caching_llama.LlamaKVCachingInputs'>, value: LlamaKVCachingInputs(tokens=<NamedArray int32(| batch:16, seq:1) (wrapping DynamicJaxprTracer)>, positions=<NamedArray int32(| batch:16, seq:1) (wrapping DynamicJaxprTracer)>, attention_mask=<NamedArray bool(| kv_seq:128, batch:16, seq:1) (wrapping DynamicJaxprTracer)>, sampling_state=LlamaKVCachingState(cache_len=128, batch_axes={'batch': 16}, kv_caches={'WithSideInputsFromInputTuple.body/LlamaTransformer.body/WithSideInputsFromInputTuple.body/Sequential.sublayers[3]/ScanSequential.layer/LlamaBlock.sublayers[1]/Residual.delta/Sequential.sublayers[2]/LlamaKVCachingAttention.kv_cache': (<NamedArray bfloat16(| batch:16, projection:128, layer:80, kv_heads:8, seq:128) (wrapping DynamicJaxprTracer)>, <NamedArray bfloat16(| batch:16, projection:128, layer:80, kv_heads:8, seq:128) (wrapping DynamicJaxprTracer)>)}, cache_end_index=Traced<ShapedArray(int32[], weak_type=True)>with<DynamicJaxprTrace(level=2/0)>)).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmicrlhf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sample\n\u001b[0;32m----> 2\u001b[0m texts, cache \u001b[38;5;241m=\u001b[39m \u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllama\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_seq_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_seq_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m       \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_only_completion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m texts\n",
      "File \u001b[0;32m~/micrlhf-progress/micrlhf/sampling.py:119\u001b[0m, in \u001b[0;36msample\u001b[0;34m(llama, tokenizer, prompt, batch_size, max_seq_len, pad_token_id, do_sample, return_model, strip_padding, return_only_completion, seed, verbose, use_jit, cache_kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m     advanced, tokens, key \u001b[38;5;241m=\u001b[39m sample_logits(logits, tokens, cache, key, do_sample\u001b[38;5;241m=\u001b[39mdo_sample)\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m (trange(max_seq_len \u001b[38;5;241m-\u001b[39m initial_length) \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_seq_len \u001b[38;5;241m-\u001b[39m initial_length)):\n\u001b[0;32m--> 119\u001b[0m         advanced, tokens, cache, key \u001b[38;5;241m=\u001b[39m \u001b[43msample_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllama_cached\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madvanced\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mbase_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffsets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_sample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m         \u001b[38;5;66;03m# bar.set_description(tokenizer.decode(tokens.untag(\"batch\", \"seq\").data_array[0]))\u001b[39;00m\n\u001b[1;32m    124\u001b[0m tokens \u001b[38;5;241m=\u001b[39m tokens\u001b[38;5;241m.\u001b[39muntag(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mdata_array\n",
      "    \u001b[0;31m[... skipping hidden 11 frame]\u001b[0m\n",
      "File \u001b[0;32m~/micrlhf-progress/micrlhf/sampling.py:50\u001b[0m, in \u001b[0;36msample_step\u001b[0;34m(llama_cached, advanced, tokens, cache, key, base_mask, offsets, do_sample)\u001b[0m\n\u001b[1;32m     42\u001b[0m max_seq_len \u001b[38;5;241m=\u001b[39m tokens\u001b[38;5;241m.\u001b[39mnamed_shape[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     43\u001b[0m inputs \u001b[38;5;241m=\u001b[39m LlamaKVCachingInputs(\n\u001b[1;32m     44\u001b[0m     tokens\u001b[38;5;241m=\u001b[39madvanced[\u001b[38;5;28;01mNone\u001b[39;00m]\u001b[38;5;241m.\u001b[39mtag(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     45\u001b[0m     positions\u001b[38;5;241m=\u001b[39mpz\u001b[38;5;241m.\u001b[39mnx\u001b[38;5;241m.\u001b[39mfull({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m: batch_size, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m}, cache\u001b[38;5;241m.\u001b[39mcache_end_index, jnp\u001b[38;5;241m.\u001b[39mint32) \u001b[38;5;241m-\u001b[39m offsets,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m     sampling_state\u001b[38;5;241m=\u001b[39mcache\n\u001b[1;32m     49\u001b[0m )\n\u001b[0;32m---> 50\u001b[0m logits, cache \u001b[38;5;241m=\u001b[39m \u001b[43mcall_llama\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllama_cached\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m advanced, tokens, key \u001b[38;5;241m=\u001b[39m sample_logits(logits, tokens, cache, key, do_sample)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m advanced, tokens, cache, key\n",
      "    \u001b[0;31m[... skipping hidden 11 frame]\u001b[0m\n",
      "File \u001b[0;32m~/micrlhf-progress/micrlhf/sampling.py:24\u001b[0m, in \u001b[0;36mcall_llama\u001b[0;34m(llama_cached, inputs)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;129m@jax\u001b[39m\u001b[38;5;241m.\u001b[39mjit\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_llama\u001b[39m(llama_cached, inputs):\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mllama_cached\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/micrlhf-progress-a058ydGG-py3.12/lib/python3.12/site-packages/penzai/core/layer.py:72\u001b[0m, in \u001b[0;36mchecked_layer_call.<locals>.wrapper\u001b[0;34m(self, argument)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, argument: Any, \u001b[38;5;241m/\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 72\u001b[0m   input_vars \u001b[38;5;241m=\u001b[39m \u001b[43mshapecheck\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_structure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m      \u001b[49m\u001b[43margument\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpattern\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m      \u001b[49m\u001b[43merror_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mError while checking the input of a layer of type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     77\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__qualname__\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     78\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m   output_structure \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_structure()\n\u001b[1;32m     81\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m jax\u001b[38;5;241m.\u001b[39mnamed_scope(\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m):\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/micrlhf-progress-a058ydGG-py3.12/lib/python3.12/site-packages/penzai/core/shapecheck.py:738\u001b[0m, in \u001b[0;36mcheck_structure\u001b[0;34m(value, pattern, known_vars, error_prefix)\u001b[0m\n\u001b[1;32m    732\u001b[0m       failed \u001b[38;5;241m=\u001b[39m _UnsatisfiedConstraint(\n\u001b[1;32m    733\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValue \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(value)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m was not equal to the non-ArraySpec\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    734\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m pattern \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(pattern)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    735\u001b[0m       )\n\u001b[1;32m    736\u001b[0m       all_constraints\u001b[38;5;241m.\u001b[39mappend((keypath, failed))\n\u001b[0;32m--> 738\u001b[0m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_map_with_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_leaf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mArraySpec\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mWildcard\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    743\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;66;03m# Phase 1: Collect and handle constraints that don't require solving for\u001b[39;00m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;66;03m# variables.\u001b[39;00m\n\u001b[1;32m    747\u001b[0m failures \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/micrlhf-progress-a058ydGG-py3.12/lib/python3.12/site-packages/jax/_src/tree_util.py:1000\u001b[0m, in \u001b[0;36mtree_map_with_path\u001b[0;34m(f, tree, is_leaf, *rest)\u001b[0m\n\u001b[1;32m    998\u001b[0m keypath_leaves, treedef \u001b[38;5;241m=\u001b[39m tree_flatten_with_path(tree, is_leaf)\n\u001b[1;32m    999\u001b[0m keypath_leaves \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mkeypath_leaves))\n\u001b[0;32m-> 1000\u001b[0m all_keypath_leaves \u001b[38;5;241m=\u001b[39m keypath_leaves \u001b[38;5;241m+\u001b[39m [\u001b[43mtreedef\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten_up_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rest]\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m treedef\u001b[38;5;241m.\u001b[39munflatten(f(\u001b[38;5;241m*\u001b[39mxs) \u001b[38;5;28;01mfor\u001b[39;00m xs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mall_keypath_leaves))\n",
      "\u001b[0;31mValueError\u001b[0m: Custom node type mismatch: expected type: <class 'micrlhf.caching_llama.LlamaKVCachingInputs'>, value: LlamaKVCachingInputs(tokens=<NamedArray int32(| batch:16, seq:1) (wrapping DynamicJaxprTracer)>, positions=<NamedArray int32(| batch:16, seq:1) (wrapping DynamicJaxprTracer)>, attention_mask=<NamedArray bool(| kv_seq:128, batch:16, seq:1) (wrapping DynamicJaxprTracer)>, sampling_state=LlamaKVCachingState(cache_len=128, batch_axes={'batch': 16}, kv_caches={'WithSideInputsFromInputTuple.body/LlamaTransformer.body/WithSideInputsFromInputTuple.body/Sequential.sublayers[3]/ScanSequential.layer/LlamaBlock.sublayers[1]/Residual.delta/Sequential.sublayers[2]/LlamaKVCachingAttention.kv_cache': (<NamedArray bfloat16(| batch:16, projection:128, layer:80, kv_heads:8, seq:128) (wrapping DynamicJaxprTracer)>, <NamedArray bfloat16(| batch:16, projection:128, layer:80, kv_heads:8, seq:128) (wrapping DynamicJaxprTracer)>)}, cache_end_index=Traced<ShapedArray(int32[], weak_type=True)>with<DynamicJaxprTrace(level=2/0)>))."
     ]
    }
   ],
   "source": [
    "from micrlhf.sampling import sample\n",
    "texts, cache = sample((llama, cache), tokenizer, prompt, batch_size=batch_size, max_seq_len=max_seq_len,\n",
    "       do_sample=True, return_only_completion=True)\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"output_0957272383054c77a03350b2ea7bce9e\"><script> /* penzai.treescope rendering of a Python object (compressed) */ (()=>{ let observer; let lastStep = new Promise((resolve, reject) => { observer = new IntersectionObserver((entries) => { for (const entry of entries) { if (entry.isIntersecting) { resolve(); observer.disconnect(); return; } } }, {rootMargin: \"1000px\"}); }); window.treescope_decompress_enqueue = (encoded, destId) => { const previous = lastStep; const destElt = document.getElementById(destId); lastStep = (async () => { await previous; let blob = new Blob([ Uint8Array.from(atob(encoded), (m) => m.codePointAt(0)) ]); let reader = blob.stream().pipeThrough( new DecompressionStream(\"deflate\") ).pipeThrough( new TextDecoderStream(\"utf-8\") ).getReader(); let parts = []; while (true) { let step = await reader.read(); if (step.done) { break; } parts.push(step.value); } let newElt = document.createElement(\"div\"); newElt.innerHTML = parts.join(\"\"); destElt.parentNode.replaceChild(newElt, destElt); for (let oldScript of newElt.querySelectorAll(\"script\")) { let newScript = document.createElement(\"script\"); newScript.type = oldScript.type; newScript.textContent = oldScript.textContent; oldScript.parentNode.replaceChild(newScript, oldScript); } })(); requestAnimationFrame(() => { observer.observe(destElt); }); } })(); </script><div id=\"compress_html_4a23c81b279d4c82a35a00fb28e682d5\"><script>window.treescope_decompress_enqueue(\"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\", \"compress_html_4a23c81b279d4c82a35a00fb28e682d5\");</script><span style=\"color: #aaaaaa; font-family: monospace\">(Loading...)</span></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"compress_html_5b1b3ffb1acd4820b8d19c7015fcb02f\"><script>window.treescope_decompress_enqueue(\"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\", \"compress_html_5b1b3ffb1acd4820b8d19c7015fcb02f\");</script></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"output_dest_0957272383054c77a03350b2ea7bce9e\"><script> (()=>{ const output = document.getElementById(\"output_0957272383054c77a03350b2ea7bce9e\"); const dest = document.getElementById(\"output_dest_0957272383054c77a03350b2ea7bce9e\"); dest.parentNode.replaceChild(output, dest); })(); </script></div>"
      ],
      "text/plain": [
       "(<NamedArray bfloat16(| batch:16, projection:128, layer:80, kv_heads:8, seq:128) ≈0.0 ±0.0 [≥0.0, ≤0.0] zero:167_772_160 (wrapping jax.Array)>,\n",
       " <NamedArray bfloat16(| batch:16, projection:128, layer:80, kv_heads:8, seq:128) ≈0.0 ±0.0 [≥0.0, ≤0.0] zero:167_772_160 (wrapping jax.Array)>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(cache.kv_caches.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micrlhf-progress-a058ydGG-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
