{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm, trange\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax_smi\n",
    "jax_smi.initialise_tracking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 2**20\n",
    "hidden_size = 2**14\n",
    "w_chunk = 2**12\n",
    "w_size = 2**20\n",
    "k = 64\n",
    "# n_dp, n_mp = 1, 4\n",
    "n_dp, n_mp = 4, 1\n",
    "input_size = input_size * n_dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_v4_chip_flops = 275 * 1e12  # https://cloud.google.com/tpu/docs/v4\n",
    "v4_8_flops = one_v4_chip_flops * 4\n",
    "chunk_flops = input_size * hidden_size * w_chunk * n_mp\n",
    "task_flops = input_size * hidden_size * w_size\n",
    "print(\"For chunk:\", chunk_flops / v4_8_flops)\n",
    "print(\"For task:\", task_flops / v4_8_flops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "devices = np.asarray(jax.local_devices()).reshape(n_dp, n_mp)\n",
    "mesh = jax.sharding.Mesh(devices, (\"dp\", \"mp\"))\n",
    "\n",
    "cpu = jax.devices(\"cpu\")[0]\n",
    "to_cpu = lambda x: jax.device_put(x, cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_enc = []\n",
    "with jax.default_device(cpu):\n",
    "    key = jax.random.key(0)\n",
    "    n_chunks = w_size // w_chunk // n_mp\n",
    "    try:\n",
    "        for _ in trange(n_chunks, postfix=\"Generating encoder weights...\"):\n",
    "            key, subkey = jax.random.split(key)\n",
    "            weights_enc.append(jax.random.randint(subkey, (hidden_size, w_chunk * n_mp), 0, 100, dtype=jnp.int8))\n",
    "    except KeyboardInterrupt:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "\n",
    "key_sharding = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(\"dp\"))\n",
    "data_sharding = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(\"dp\", None))\n",
    "weight_sharding = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(None, \"mp\"))\n",
    "topk_sharding = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(\"dp\", \"mp\"))\n",
    "# single_mesh = jax.sharding.Mesh(devices[:1, :], (\"dp\", \"mp\"))\n",
    "# single_sharding = jax.sharding.NamedSharding(single_mesh, jax.sharding.PartitionSpec(None, \"mp\"))\n",
    "\n",
    "def gen_inputs(input_key):\n",
    "    input_key, subkey = jax.vmap(jax.random.split, in_axes=0, out_axes=1)(input_key)\n",
    "    # inputs = jax.random.uniform(subkey, (input_size, hidden_size), jnp.bfloat16)\n",
    "    inputs = jnp.ones((input_size, hidden_size), jnp.int8)\n",
    "    return inputs, input_key\n",
    "gen_inputs_jit = jax.jit(gen_inputs, in_shardings=(key_sharding,), out_shardings=(data_sharding, key_sharding), donate_argnums=(0,))\n",
    "\n",
    "def matmul_topk(inputs, weight_chunk, old_weights, old_indices):\n",
    "    output_chunk = inputs @ weight_chunk\n",
    "    # weights, indices = jax.lax.top_k(output_chunk, k=k)\n",
    "    # weights, indices = jax.lax.approx_max_k(output_chunk, k=k)\n",
    "    weights, indices = jax.lax.approx_max_k(output_chunk.astype(jnp.bfloat16), k=k, recall_target=0.8)\n",
    "    # weights, indices = jax.lax.approx_max_k(output_chunk, k=k, recall_target=0.5)\n",
    "    # weights, indices = jax.lax.approx_max_k(output_chunk, k=k, recall_target=0.25)\n",
    "    \n",
    "    # _, indices = jax.lax.approx_max_k(output_chunk[:, :k * 4], k=k)\n",
    "    # _, indices = jax.lax.approx_max_k(output_chunk[:, :k], k=k)\n",
    "    # weights = output_chunk.reshape(output_chunk.shape[0], k, -1).sum(-1)\n",
    "    # weights, indices = jax.lax.top_k(output_chunk, k=k)\n",
    "    \n",
    "    if old_weights is None or old_indices is None:\n",
    "        return weights, indices\n",
    "    else:\n",
    "        # replace_mask = weights > old_weights\n",
    "        # return jnp.where(replace_mask, weights, old_weights), jnp.where(replace_mask, indices, old_indices)\n",
    "\n",
    "        new_full_weights = jnp.concatenate((weights, old_weights), axis=1)\n",
    "        new_full_indices = jnp.concatenate((indices, old_indices), axis=1)\n",
    "        \n",
    "        # over_indices = jnp.argsort(new_full_weights)[:, -k:]\n",
    "        # return jnp.take_along_axis(new_full_weights, over_indices, axis=1), jnp.take_along_axis(new_full_indices, over_indices, axis=1)\n",
    "        \n",
    "        _, over_indices = jax.lax.top_k(new_full_weights, k=k)\n",
    "        return jnp.take_along_axis(new_full_weights, over_indices, axis=1), jnp.take_along_axis(new_full_indices, over_indices, axis=1)\n",
    "\n",
    "matmul_topk_jit = jax.jit(matmul_topk, in_shardings=(data_sharding, weight_sharding, topk_sharding, topk_sharding), out_shardings=(topk_sharding, topk_sharding), donate_argnums=(2, 3))\n",
    "\n",
    "# weights_0_put = jax.device_put(weights_enc[0], weight_sharding)\n",
    "# send_weights = lambda _: weights_0_put\n",
    "def send_weights(weights):\n",
    "    # weights = jax.device_put(weights, single_sharding)\n",
    "    return jax.device_put(weights, weight_sharding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_key = jax.device_put(jax.random.split(jax.random.key(0), mesh.shape[\"dp\"]), key_sharding)\n",
    "# %time inputs, input_key = jax.block_until_ready(gen_inputs_jit(input_key))\n",
    "\n",
    "\n",
    "# for idx in trange(3):\n",
    "#     %time current_chunk = jax.block_until_ready(send_weights(weights_enc[idx]))\n",
    "#     %time inputs.block_until_ready()\n",
    "#     %time current_chunk.block_until_ready()\n",
    "#     %time weights, indices = jax.block_until_ready(matmul_topk_jit(inputs, current_chunk))\n",
    "# compiled = matmul_topk_jit.lower(inputs, current_chunk).compile()\n",
    "# estimated_chunk_flops = compiled.cost_analysis()[0]['flops']\n",
    "# print(\"Our flops estimate:\", estimated_chunk_flops / v4_8_flops)\n",
    "# print(\"Estimate from compiler:\", compiled.cost_analysis()[0][\"optimal_seconds\"])\n",
    "# for name in (\"current_chunk\", \"next_chunk\", \"weights\", \"indices\", \"inputs\"):\n",
    "#     try:\n",
    "#         del globals()[name]\n",
    "#     except KeyError:\n",
    "#         pass\n",
    "#     gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul_trial(inputs):\n",
    "    current_chunk = send_weights(weights_enc[0])\n",
    "    weights, indices = None, None\n",
    "    bar = tqdm(weights_enc[1:], postfix=f\"Trial {trial}, encoder forward pass\")\n",
    "    for cpu_enc_chunk in bar:\n",
    "        next_chunk = send_weights(cpu_enc_chunk)\n",
    "\n",
    "        weights, indices = matmul_topk_jit(inputs, current_chunk, weights, indices)\n",
    "        \n",
    "        current_chunk = next_chunk\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "if \"inputs\" in globals():\n",
    "    del inputs\n",
    "    gc.collect()\n",
    "input_key = jax.device_put(jax.random.split(jax.random.key(0), mesh.shape[\"dp\"]), key_sharding)\n",
    "for trial in trange(100, postfix=\"Measuring forward speed...\"):\n",
    "    inputs, input_key = gen_inputs_jit(input_key)\n",
    "    matmul_trial(inputs)\n",
    "    del inputs\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in (\"current_chunk\", \"next_chunk\", \"weights\", \"indices\", \"inputs\"):\n",
    "    try:\n",
    "        del globals()[name]\n",
    "    except KeyError:\n",
    "        pass\n",
    "    gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micrlhf-progress-a058ydGG-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
