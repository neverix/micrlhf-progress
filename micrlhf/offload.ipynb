{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm, trange\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax_smi\n",
    "jax_smi.initialise_tracking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 2**19 + 2**18\n",
    "hidden_size = 2**14\n",
    "w_chunk = 2**12\n",
    "w_size = 2**20\n",
    "k = 64\n",
    "# n_dp, n_mp = 1, 4\n",
    "n_dp, n_mp = 4, 1\n",
    "input_size = input_size * n_dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For chunk: 0.19191475684817455\n",
      "For task: 49.130177753132685\n"
     ]
    }
   ],
   "source": [
    "one_v4_chip_flops = 275 * 1e12  # https://cloud.google.com/tpu/docs/v4\n",
    "v4_8_flops = one_v4_chip_flops * 4\n",
    "chunk_flops = input_size * hidden_size * w_chunk * n_mp\n",
    "task_flops = input_size * hidden_size * w_size\n",
    "print(\"For chunk:\", chunk_flops / v4_8_flops)\n",
    "print(\"For task:\", task_flops / v4_8_flops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4 (inner):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neverix/.cache/pypoetry/virtualenvs/micrlhf-progress-a058ydGG-py3.10/lib/python3.10/site-packages/jax/_src/xla_bridge.py\", line 884, in backends\n",
      "    backend = _init_backend(platform)\n",
      "  File \"/home/neverix/.cache/pypoetry/virtualenvs/micrlhf-progress-a058ydGG-py3.10/lib/python3.10/site-packages/jax/_src/xla_bridge.py\", line 975, in _init_backend\n",
      "    backend = registration.factory()\n",
      "  File \"/home/neverix/.cache/pypoetry/virtualenvs/micrlhf-progress-a058ydGG-py3.10/lib/python3.10/site-packages/jax/_src/xla_bridge.py\", line 146, in tpu_client_timer_callback\n",
      "    client = xla_client.make_tpu_client(\n",
      "  File \"/home/neverix/.cache/pypoetry/virtualenvs/micrlhf-progress-a058ydGG-py3.10/lib/python3.10/site-packages/jaxlib/xla_client.py\", line 210, in make_tpu_client\n",
      "    return make_tfrt_tpu_c_api_client(options)\n",
      "  File \"/home/neverix/.cache/pypoetry/virtualenvs/micrlhf-progress-a058ydGG-py3.10/lib/python3.10/site-packages/jaxlib/xla_client.py\", line 132, in make_tfrt_tpu_c_api_client\n",
      "    return _xla.get_c_api_client('tpu', options)\n",
      "jaxlib.xla_extension.XlaRuntimeError: UNKNOWN: TPU initialization failed: open(/dev/accel0): Operation not permitted: Operation not permitted; Couldn't open device: /dev/accel0; [/dev/accel0] \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/neverix/.cache/pypoetry/virtualenvs/micrlhf-progress-a058ydGG-py3.10/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/neverix/.cache/pypoetry/virtualenvs/micrlhf-progress-a058ydGG-py3.10/lib/python3.10/site-packages/jax_smi/initialise_tracking.py\", line 9, in inner\n",
      "    jax.profiler.save_device_memory_profile(f'{dir_prefix}/memory.prof.new')\n",
      "  File \"/home/neverix/.cache/pypoetry/virtualenvs/micrlhf-progress-a058ydGG-py3.10/lib/python3.10/site-packages/jax/_src/profiler.py\", line 381, in save_device_memory_profile\n",
      "    profile = device_memory_profile(backend)\n",
      "  File \"/home/neverix/.cache/pypoetry/virtualenvs/micrlhf-progress-a058ydGG-py3.10/lib/python3.10/site-packages/jax/_src/profiler.py\", line 366, in device_memory_profile\n",
      "    return xla_client.heap_profile(xla_bridge.get_backend(backend))\n",
      "  File \"/home/neverix/.cache/pypoetry/virtualenvs/micrlhf-progress-a058ydGG-py3.10/lib/python3.10/site-packages/jax/_src/xla_bridge.py\", line 1021, in get_backend\n",
      "    return _get_backend_uncached(platform)\n",
      "  File \"/home/neverix/.cache/pypoetry/virtualenvs/micrlhf-progress-a058ydGG-py3.10/lib/python3.10/site-packages/jax/_src/xla_bridge.py\", line 1000, in _get_backend_uncached\n",
      "    bs = backends()\n",
      "  File \"/home/neverix/.cache/pypoetry/virtualenvs/micrlhf-progress-a058ydGG-py3.10/lib/python3.10/site-packages/jax/_src/xla_bridge.py\", line 900, in backends\n",
      "    raise RuntimeError(err_msg)\n",
      "RuntimeError: Unable to initialize backend 'tpu': UNKNOWN: TPU initialization failed: open(/dev/accel0): Operation not permitted: Operation not permitted; Couldn't open device: /dev/accel0; [/dev/accel0]  (set JAX_PLATFORMS='' to automatically choose an available backend)\n"
     ]
    }
   ],
   "source": [
    "devices = np.asarray(jax.local_devices()).reshape(n_dp, n_mp)\n",
    "mesh = jax.sharding.Mesh(devices, (\"dp\", \"mp\"))\n",
    "\n",
    "cpu = jax.devices(\"cpu\")[0]\n",
    "to_cpu = lambda x: jax.device_put(x, cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4a4b565dc8b4c3e95a8fe6a680aa9ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/256 [00:00<?, ?it/s, Generating encoder weights...]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights_enc = []\n",
    "weights_dec = []\n",
    "with jax.default_device(cpu):\n",
    "    key = jax.random.key(0)\n",
    "    n_chunks = w_size // w_chunk // n_mp\n",
    "    try:\n",
    "        for _ in trange(n_chunks, postfix=\"Generating encoder weights...\"):\n",
    "            key, subkey = jax.random.split(key)\n",
    "            scale = hidden_size ** -0.5 / 128\n",
    "            weights_enc.append(jax.random.uniform(subkey, (hidden_size, w_chunk * n_mp), dtype=jnp.bfloat16, minval=-scale, maxval=scale))\n",
    "            for _ in range(n_mp):\n",
    "                key, subkey = jax.random.split(key)\n",
    "                weights_dec.append(jax.random.uniform(subkey, (w_chunk, hidden_size), dtype=jnp.bfloat16, minval=-scale, maxval=scale))\n",
    "    except KeyboardInterrupt:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_dec = jax.jit(lambda x: jnp.concatenate(x, axis=0), backend=\"cpu\")(weights_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "\n",
    "# key_sharding = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(\"dp\"))\n",
    "key_sharding = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec())\n",
    "data_sharding = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(\"dp\", None))\n",
    "weight_sharding = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(None, \"mp\"))\n",
    "topk_sharding = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(\"dp\", \"mp\"))\n",
    "# single_mesh = jax.sharding.Mesh(devices[:1, :], (\"dp\", \"mp\"))\n",
    "# single_sharding = jax.sharding.NamedSharding(single_mesh, jax.sharding.PartitionSpec(None, \"mp\"))\n",
    "\n",
    "def split(key):\n",
    "    a, b = jax.random.split(key)\n",
    "    return a, b\n",
    "\n",
    "def gen_inputs(input_key):\n",
    "    # input_key, subkey = split(input_key)\n",
    "    input_key, subkey = input_key + 1, input_key\n",
    "    \n",
    "    # inputs = jax.vmap(lambda x: jax.random.randint(x, (input_size // mesh.shape[\"dp\"], hidden_size), -100, 100, jnp.int8))(subkey).reshape(input_size, hidden_size)\n",
    "    # inputs = jax.random.randint(subkey, (input_size, hidden_size), -100, 100, jnp.int8)\n",
    "    # inputs = jax.random.bits(subkey, shape=(input_size, hidden_size), dtype=jnp.uint8)\n",
    "    inputs = jax.lax.broadcasted_iota(jnp.int4, (input_size, hidden_size), 0).astype(jnp.int8) + jax.lax.broadcasted_iota(jnp.int4, (input_size, hidden_size), 1).astype(jnp.int8) + subkey\n",
    "    # inputs = jnp.ones((input_size, hidden_size), jnp.int8)\n",
    "    return inputs, input_key\n",
    "gen_inputs_jit = jax.jit(gen_inputs, in_shardings=(key_sharding,), out_shardings=(data_sharding, key_sharding), donate_argnums=(0,))\n",
    "\n",
    "def matmul_topk(inputs, weight_chunk, old_weights, old_indices, offset):\n",
    "    output_chunk = inputs @ weight_chunk\n",
    "    # weights, indices = jax.lax.top_k(output_chunk, k=k)\n",
    "    # weights, indices = jax.lax.approx_max_k(output_chunk, k=k)\n",
    "    weights, indices = jax.lax.approx_max_k(output_chunk.astype(jnp.bfloat16), k=k, recall_target=0.8)\n",
    "    indices += offset\n",
    "    # weights, indices = jax.lax.approx_max_k(output_chunk, k=k, recall_target=0.5)\n",
    "    # weights, indices = jax.lax.approx_max_k(output_chunk, k=k, recall_target=0.25)\n",
    "    \n",
    "    # _, indices = jax.lax.approx_max_k(output_chunk[:, :k * 4], k=k)\n",
    "    # _, indices = jax.lax.approx_max_k(output_chunk[:, :k], k=k)\n",
    "    # weights = output_chunk.reshape(output_chunk.shape[0], k, -1).sum(-1)\n",
    "    # weights, indices = jax.lax.top_k(output_chunk, k=k)\n",
    "    \n",
    "    if old_weights is None or old_indices is None:\n",
    "        return weights, indices\n",
    "    else:\n",
    "        # replace_mask = weights > old_weights\n",
    "        # return jnp.where(replace_mask, weights, old_weights), jnp.where(replace_mask, indices, old_indices)\n",
    "\n",
    "        new_full_weights = jnp.concatenate((weights, old_weights), axis=1)\n",
    "        new_full_indices = jnp.concatenate((indices, old_indices), axis=1)\n",
    "        \n",
    "        # over_indices = jnp.argsort(new_full_weights)[:, -k:]\n",
    "        # return jnp.take_along_axis(new_full_weights, over_indices, axis=1), jnp.take_along_axis(new_full_indices, over_indices, axis=1)\n",
    "        \n",
    "        _, over_indices = jax.lax.top_k(new_full_weights, k=k)\n",
    "        return jnp.take_along_axis(new_full_weights, over_indices, axis=1), jnp.take_along_axis(new_full_indices, over_indices, axis=1)\n",
    "\n",
    "matmul_topk_jit = jax.jit(matmul_topk, in_shardings=(data_sharding, weight_sharding, topk_sharding, topk_sharding, None), out_shardings=(topk_sharding, topk_sharding), donate_argnums=(2, 3))\n",
    "\n",
    "# weights_0_put = jax.device_put(weights_enc[0], weight_sharding)\n",
    "# send_weights = lambda _: weights_0_put\n",
    "def send_weights(weights):\n",
    "    # weights = jax.device_put(weights, single_sharding)\n",
    "    return jax.device_put(weights, weight_sharding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_key = jax.device_put(jax.random.split(jax.random.key(0), mesh.shape[\"dp\"]), key_sharding)\n",
    "# %time inputs, input_key = jax.block_until_ready(gen_inputs_jit(input_key))\n",
    "\n",
    "\n",
    "# for idx in trange(3):\n",
    "#     %time current_chunk = jax.block_until_ready(send_weights(weights_enc[idx]))\n",
    "#     %time inputs.block_until_ready()\n",
    "#     %time current_chunk.block_until_ready()\n",
    "#     %time weights, indices = jax.block_until_ready(matmul_topk_jit(inputs, current_chunk))\n",
    "# compiled = matmul_topk_jit.lower(inputs, current_chunk).compile()\n",
    "# estimated_chunk_flops = compiled.cost_analysis()[0]['flops']\n",
    "# print(\"Our flops estimate:\", estimated_chunk_flops / v4_8_flops)\n",
    "# print(\"Estimate from compiler:\", compiled.cost_analysis()[0][\"optimal_seconds\"])\n",
    "# for name in (\"current_chunk\", \"next_chunk\", \"weights\", \"indices\", \"inputs\"):\n",
    "#     try:\n",
    "#         del globals()[name]\n",
    "#     except KeyError:\n",
    "#         pass\n",
    "#     gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_matmul_inner(weights, indices, decoder_weight):\n",
    "    out = (weights.astype(jnp.float32) @ decoder_weight[indices].astype(jnp.float32)).astype(jnp.bfloat16)\n",
    "    return out\n",
    "\n",
    "\n",
    "def sparse_matmul(weights, indices, decoder_weight):\n",
    "    out = jax.lax.map(lambda xs: sparse_matmul_inner(*xs, decoder_weight=decoder_weight), (weights, indices), batch_size=w_chunk)\n",
    "    return out\n",
    "\n",
    "\n",
    "sparse_matmul_jit = jax.jit(sparse_matmul, backend=\"cpu\")\n",
    "# %time result = sparse_matmul_jit(encback[0], encback[1], weight_dec)\n",
    "# %time result.block_until_ready();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "from queue import Queue\n",
    "\n",
    "def sparse_matmul_async(weights, indices):\n",
    "    out_queue = Queue()\n",
    "    def worker():\n",
    "        out_queue.put(sparse_matmul_jit(weights, indices, weight_dec))\n",
    "    thread = Thread(target=worker)\n",
    "    thread.start()\n",
    "    return out_queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c0dfa1608a243d3a770b6b957672e1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s, Measuring forward speed...]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be0a620b705f4dedaf7d7099ea69e78d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s, Encoder forward pass]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for encoder...\n",
      "Encoder time: 63.6133930683136\n",
      "Encoder to CPU time: 32.18491768836975\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43b95e06abb8459e8e3043a1c6c18884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s, Encoder forward pass]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing decoder...\n",
      "Decoder time: 622.9597156047821\n",
      "(3145728, 16384) -3.21865e-06 3.43323e-05 (3145728, 16384)\n",
      "Waiting for encoder...\n",
      "Encoder time: 0.0024099349975585938\n",
      "Encoder to CPU time: 33.257750034332275\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beb239ab590c46d59aa68dab4ae08341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s, Encoder forward pass]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing decoder...\n",
      "Decoder time: 579.9662253856659\n",
      "(3145728, 16384) -2.96533e-06 3.09944e-05 (3145728, 16384)\n",
      "Waiting for encoder...\n",
      "Encoder time: 0.0003921985626220703\n",
      "Encoder to CPU time: 35.19124937057495\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0bc68e876fe4c3699f8dc1a01b79f69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s, Encoder forward pass]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing decoder...\n",
      "Decoder time: 629.5328481197357\n",
      "(3145728, 16384) -2.77162e-06 2.82526e-05 (3145728, 16384)\n",
      "Waiting for encoder...\n",
      "Encoder time: 0.0004093647003173828\n",
      "Encoder to CPU time: 27.978961944580078\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac6ad03e4ddc46bb93a3b9931e805e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s, Encoder forward pass]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing decoder...\n",
      "Decoder time: 654.6574959754944\n",
      "(3145728, 16384) -2.6226e-06 2.61068e-05 (3145728, 16384)\n",
      "Waiting for encoder...\n",
      "Encoder time: 0.0015304088592529297\n",
      "Encoder to CPU time: 30.460320949554443\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69d8eedaf5a545d68018c924045a137a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s, Encoder forward pass]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing decoder...\n",
      "Decoder time: 660.190767288208\n",
      "(3145728, 16384) -2.5332e-06 2.46763e-05 (3145728, 16384)\n",
      "Waiting for encoder...\n",
      "Encoder time: 0.0015575885772705078\n",
      "Encoder to CPU time: 30.88784694671631\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "283b6fccc1bb423c901956f14a3aeaad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s, Encoder forward pass]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing decoder...\n",
      "Decoder time: 668.5194637775421\n",
      "(3145728, 16384) -2.48849e-06 2.38419e-05 (3145728, 16384)\n",
      "Waiting for encoder...\n",
      "Encoder time: 0.00023746490478515625\n",
      "Encoder to CPU time: 28.306641340255737\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3904b2b65334b7cae36578941c7879d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s, Encoder forward pass]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing decoder...\n",
      "Decoder time: 613.2252752780914\n",
      "(3145728, 16384) -2.5034e-06 2.37226e-05 (3145728, 16384)\n",
      "Waiting for encoder...\n",
      "Encoder time: 0.0003528594970703125\n",
      "Encoder to CPU time: 34.536378383636475\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96a802870c294029a2bba0c4ca24e19f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s, Encoder forward pass]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing decoder...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 50\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncoder to CPU time:\u001b[39m\u001b[38;5;124m\"\u001b[39m, after_to_cpu \u001b[38;5;241m-\u001b[39m after_compute)\n\u001b[1;32m     48\u001b[0m         encodings \u001b[38;5;241m=\u001b[39m weights, indices\n\u001b[0;32m---> 50\u001b[0m \u001b[43mtrial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 34\u001b[0m, in \u001b[0;36mtrial\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputing decoder...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m decoder_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 34\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_outputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mblock_until_ready()\n\u001b[1;32m     35\u001b[0m decoder_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecoder time:\u001b[39m\u001b[38;5;124m\"\u001b[39m, decoder_end \u001b[38;5;241m-\u001b[39m decoder_start)\n",
      "File \u001b[0;32m/usr/lib/python3.10/queue.py:171\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qsize():\n\u001b[0;32m--> 171\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be a non-negative number\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import queue\n",
    "import time\n",
    "\n",
    "\n",
    "def matmul_trial(inputs):\n",
    "    current_chunk = send_weights(weights_enc[0])\n",
    "    weights, indices = None, None\n",
    "    bar = tqdm(weights_enc[::8], postfix=f\"Encoder forward pass\")\n",
    "    offset = 0\n",
    "    for cpu_enc_chunk in bar:\n",
    "        next_chunk = send_weights(cpu_enc_chunk)\n",
    "        weights, indices = matmul_topk_jit(inputs, current_chunk, weights, indices, offset)\n",
    "        offset += cpu_enc_chunk.shape[1]\n",
    "        current_chunk = next_chunk\n",
    "        gc.collect()\n",
    "    return weights, indices\n",
    "\n",
    "\n",
    "def trial():\n",
    "    gc.collect()\n",
    "    input_key = 0  # jax.random.split(jax.random.key(0), mesh.shape[\"dp\"])\n",
    "    encodings, past_inputs, decoder_outputs = None, None, None\n",
    "    for _ in trange(100, postfix=\"Measuring forward speed...\"):\n",
    "        gc.collect()\n",
    "        if encodings is not None:\n",
    "            decoder_outputs = sparse_matmul_async(encodings[0], encodings[1])\n",
    "            past_inputs = inputs\n",
    "        inputs, input_key = gen_inputs_jit(input_key)\n",
    "        weights, indices = matmul_trial(inputs)\n",
    "        if decoder_outputs is not None:\n",
    "            print(\"Computing decoder...\")\n",
    "            decoder_start = time.time()\n",
    "            decoder_outputs = decoder_outputs.get().block_until_ready()\n",
    "            decoder_end = time.time()\n",
    "            print(\"Decoder time:\", decoder_end - decoder_start)\n",
    "            print(decoder_outputs.shape, decoder_outputs.mean(), decoder_outputs.std(), past_inputs.shape)\n",
    "            past_inputs, decoder_outputs = None, None\n",
    "            gc.collect()\n",
    "        print(\"Waiting for encoder...\")\n",
    "        before_compute = time.time()\n",
    "        weights, indices = weights.block_until_ready(), indices.block_until_ready()\n",
    "        after_compute = time.time()\n",
    "        print(\"Encoder time:\", (after_compute - before_compute))\n",
    "        weights, indices = to_cpu(weights), to_cpu(indices)\n",
    "        after_to_cpu = time.time()\n",
    "        print(\"Encoder to CPU time:\", after_to_cpu - after_compute)\n",
    "        encodings = weights, indices\n",
    "\n",
    "trial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_array_np = np.asarray(encback[1].ravel())\n",
    "# weight_array_np = np.asarray(encback[0].ravel().view(jnp.float16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import trange\n",
    "# masks = []\n",
    "# chunked_weights = []\n",
    "# chunked_indices = []\n",
    "# for i in trange(0, w_size, w_chunk):\n",
    "#     mask = (i < index_array_np) & (index_array_np < (i + w_chunk))\n",
    "#     chunked_indices.append(index_array_np[mask] - i)\n",
    "#     chunked_weights.append(weight_array_np[mask])\n",
    "#     masks.append(np.nonzero(mask)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "# plt.hist([x.shape[0] for x in chunked_indices])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64cced2e3960423189c684a36593a00f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b_chunk = 2**12\n",
    "for idx in trange(0, w_size, b_chunk):\n",
    "    sparse_matmul_out = sparse_matmul_jit(*(u[idx:idx + b_chunk] for u in encback), weight_dec)\n",
    "    del sparse_matmul_out\n",
    "    gc.collect()\n",
    "# %time sparse_matmul_out = sparse_matmul_jit(*encback, weight_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4194304, 64), (4194304, 64))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encback[0].shape, encback[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096, 16384)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_dec[0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micrlhf-progress-a058ydGG-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
