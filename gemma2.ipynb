{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import penzai\n",
    "from penzai import pz\n",
    "pz.ts.register_as_default()\n",
    "pz.ts.register_autovisualize_magic()\n",
    "pz.enable_interactive_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from micrlhf.llama import LlamaTransformer\n",
    "llama = LlamaTransformer.from_pretrained(\"models/gemma-2-9b-it.gguf\", device_map=\"tpu:0\",\n",
    "                                         from_type=\"gemma2\",\n",
    "                                         load_eager=True\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"UCLA-AGI/Gemma-2-9B-It-SPPO-Iter3\")\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import jax.numpy as jnp\n",
    "# import jax\n",
    "# from micrlhf.llama import LlamaBlock\n",
    "\n",
    "# tokens = tokenizer.encode(\"The quick brown fox jumps over the lazy dog\")\n",
    "# get_resids = llama.select().at_instances_of(LlamaBlock).apply_with_selected_index(lambda i, x:\n",
    "#     pz.nn.Sequential([\n",
    "#         pz.de.TellIntermediate.from_config(tag=f\"resid_pre_{i}\"),\n",
    "#         x\n",
    "#     ])\n",
    "# )\n",
    "# get_resids = pz.de.CollectingSideOutputs.handling(get_resids, tag_predicate=lambda x: x.startswith(\"resid_pre\"))\n",
    "# token_array = jnp.asarray([tokens] * 4)\n",
    "# token_array = jax.device_put(token_array, jax.sharding.NamedSharding(llama.mesh, jax.sharding.PartitionSpec(\"dp\", \"sp\")))\n",
    "# token_array = pz.nx.wrap(token_array, \"batch\", \"seq\")\n",
    "# inputs = llama.inputs.from_basic_segments(token_array)\n",
    "# get_resids(inputs)[1][0].value.unwrap(\"batch\", \"seq\", \"embedding\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62554cdb16db4bc9b7a40479ee1eac78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script> (()=>{ if (customElements.get('treescope-container') === undefined) { class TreescopeContainer extends HTMLElement { constructor() { super(); this.attachShadow({mode: \"open\"}); this.defns = {}; this.state = {}; } } customElements.define(\"treescope-container\", TreescopeContainer); } if (customElements.get('treescope-run-here') === undefined) { class RunHere extends HTMLElement { constructor() { super() } connectedCallback() { const run = child => { const fn = new Function(child.textContent); child.textContent = \"\"; fn.call(this); this.remove(); }; const child = this.querySelector(\"script\"); if (child) { run(child); } else { new MutationObserver(()=>{ run(this.querySelector(\"script\")); }).observe(this, {childList: true}); } } } customElements.define(\"treescope-run-here\", RunHere); } })(); </script> <treescope-container class=\"treescope_out_7cf4b5575141417eb217a1fbab363a0c\" ></treescope-container> <treescope-run-here><script type=\"application/octet-stream\"> const root = ( Array.from(document.getElementsByClassName( \"treescope_out_7cf4b5575141417eb217a1fbab363a0c\")) .filter((elt) => !elt.dataset.setup) )[0]; root.dataset.setup = 1; const msg = document.createElement(\"span\"); msg.style = \"color: #aaaaaa; font-family: monospace; transition: opacity 0.2s; opacity: 0.0;\"; msg.textContent = \"(Loading...)\"; root.state.loadingMsg = msg; root.shadowRoot.appendChild(msg); root.state.chain = new Promise((resolve, reject) => { const observer = new IntersectionObserver((entries) => { for (const entry of entries) { if (entry.isIntersecting) { resolve(); observer.disconnect(); return; } } }, {rootMargin: \"1000px\"}); window.setTimeout(() => { if (root.loadingMsg) { root.loadingMsg.style.opacity = \"1.0\"; } observer.observe(root); }, 0); }); root.state.deferring = false; const _insertNode = (node) => { for (let oldScript of node.querySelectorAll(\"script\")) { let newScript = document.createElement(\"script\"); newScript.type = oldScript.type; newScript.textContent = oldScript.textContent; oldScript.parentNode.replaceChild(newScript, oldScript); } if (root.state.loadingMsg) { root.state.loadingMsg.remove(); root.state.loadingMsg = null; } root.shadowRoot.appendChild(node); }; root.defns.insertContent = ((contentNode, compressed) => { if (compressed) { root.state.deferring = true; } if (root.state.deferring) { root.state.chain = (async () => { await root.state.chain; if (compressed) { const encoded = contentNode.textContent; const blob = new Blob([ Uint8Array.from(atob(encoded), (m) => m.codePointAt(0)) ]); const reader = blob.stream().pipeThrough( new DecompressionStream(\"deflate\") ).pipeThrough( new TextDecoderStream(\"utf-8\") ).getReader(); const parts = []; while (true) { const step = await reader.read(); if (step.done) { break; } parts.push(step.value); } const tpl = document.createElement('template'); tpl.innerHTML = parts.join(\"\"); _insertNode(tpl.content); } else { _insertNode(contentNode.content); } })(); } else { _insertNode(contentNode.content); } }); </script></treescope-run-here><div style=\"display:none\"> <script type=\"application/octet-stream\" >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</script> <treescope-run-here><script type=\"application/octet-stream\"> const root = ( Array.from(document.getElementsByClassName( \"treescope_out_7cf4b5575141417eb217a1fbab363a0c\")) .filter((elt) => !elt.dataset['step0']) )[0]; root.dataset['step0'] = 1; root.defns.insertContent( this.parentNode.querySelector('script[type=\"application/octet-stream\"]'), true ); this.parentNode.remove(); </script></treescope-run-here> </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<treescope-run-here><script type=\"application/octet-stream\"> const root = ( Array.from(document.getElementsByClassName( \"treescope_out_7cf4b5575141417eb217a1fbab363a0c\")) .filter((elt) => !elt.dataset.stolen) )[0]; root.dataset.stolen = 1; this.parentNode.replaceChild(root, this); </script></treescope-run-here>"
      ],
      "text/plain": [
       "['<bos><bos><start_of_turn>user\\nWrite a hello world program<end_of_turn>\\n<start_of_turn>model\\n```python\\nprint(\"Hello, world!\")\\n```\\n\\nThis program will print the phrase \"Hello, world!\" to the console.\\n\\n**Explanation:**\\n\\n* `print()` is a built-in function in Python that displays text on the',\n",
       " '<bos><bos><start_of_turn>user\\nWrite a hello world program<end_of_turn>\\n<start_of_turn>model\\n```python\\nprint(\"Hello, world!\")\\n```\\n\\nThis program, when run in a Python interpreter, will output the following:\\n\\n```\\nHello, world!\\n```\\n\\n**Explanation:**\\n\\n* **`print()`** is a',\n",
       " '<bos><bos><start_of_turn>user\\nWrite a hello world program<end_of_turn>\\n<start_of_turn>model\\n```python\\nprint(\"Hello, world!\")\\n```\\n\\nThis program, when run, will simply print the text \"Hello, world!\" to the console. \\n\\n**Explanation:**\\n\\n* `print()` is a built-in function in',\n",
       " '<bos><bos><start_of_turn>user\\nWrite a hello world program<end_of_turn>\\n<start_of_turn>model\\n```python\\nprint(\"Hello, world!\")\\n```\\n\\nThis program will print the text \"Hello, world!\" to the console when executed. \\n\\nHere\\'s how it works:\\n\\n* `print()` is a built-in function']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from micrlhf.sampling import sample\n",
    "chat = [\n",
    "    { \"role\": \"user\", \"content\": \"Write a hello world program\" },\n",
    "]\n",
    "prompt = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
    "sample(llama, tokenizer, prompt,\n",
    "       batch_size=4, do_sample=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample(llama, tokenizer, [\"Write me a poem about Machine Learning.\", \"Hi!\"], do_sample=True, return_only_completion=True, seed=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoModelForCausalLM\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"alpindale/gemma-2b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from collections import OrderedDict\n",
    "# for m in model.modules():\n",
    "#     m._forward_hooks = OrderedDict()\n",
    "# model.model.layers[0].register_forward_hook(lambda self, input, output: print(input[0]))\n",
    "# tt = torch.LongTensor(tokens).unsqueeze(0)\n",
    "# model(tt).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micrlhf-progress-a058ydGG-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
