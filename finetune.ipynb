{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from transformers import AutoTokenizer\n",
    "from post_loader import PostLoader\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nvidia/Llama3-ChatQA-1.5-70B\")\n",
    "plt.figure(figsize=(20, 20))\n",
    "names = []\n",
    "lengths = []\n",
    "pl = PostLoader(tokenizer)\n",
    "# print([v for k, v in pl.posts.items() if \"roko\" in k and \"hara\" in k])\n",
    "for a, e in pl:\n",
    "    names.append(a)\n",
    "    lengths.append(len(tokenizer.encode(e)))\n",
    "    if \"inter\" in a:\n",
    "        t = tokenizer.encode(e)\n",
    "        w = 8192\n",
    "        print(tokenizer.decode(t[random.randrange(len(t) - w):][:w]))\n",
    "# print(len(lengths))\n",
    "plt.barh(np.argsort(np.argsort(lengths)), lengths,)\n",
    "plt.yticks(np.argsort(np.argsort(lengths)), names)\n",
    "plt.savefig(\"data/post_lengths\")\n",
    "9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micrlhf-progress-a058ydGG-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
