{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import penzai\n",
    "from penzai import pz\n",
    "pz.ts.register_as_default()\n",
    "pz.ts.register_autovisualize_magic()\n",
    "pz.enable_interactive_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/gemma-2b.gguf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmicrlhf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllama\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LlamaTransformer\n\u001b[0;32m----> 2\u001b[0m llama \u001b[38;5;241m=\u001b[39m \u001b[43mLlamaTransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels/gemma-2b.gguf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtpu:0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mfrom_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgemma\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                        \u001b[49m\u001b[38;5;66;43;03m#  load_eager=True\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micrlhf-progress/micrlhf/llama.py:355\u001b[0m, in \u001b[0;36mLlamaTransformer.from_pretrained\u001b[0;34m(cls, gguf_path, from_type, device_map, extract_layer, load_eager, transpose_rotary)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pretrained\u001b[39m(\u001b[38;5;28mcls\u001b[39m, gguf_path: os\u001b[38;5;241m.\u001b[39mPathLike \u001b[38;5;241m|\u001b[39m Iterable[os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[1;32m    349\u001b[0m                     from_type: Literal[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemma\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    350\u001b[0m                     device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m, extract_layer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    351\u001b[0m                     load_eager\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    352\u001b[0m                     transpose_rotary: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    353\u001b[0m     mesh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmake_mesh(device_map)\n\u001b[0;32m--> 355\u001b[0m     gguf \u001b[38;5;241m=\u001b[39m \u001b[43mread_gguf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgguf_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m from_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemma\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    357\u001b[0m         gguf\u001b[38;5;241m.\u001b[39mreplace_metadata_prefix(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemma.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/micrlhf-progress/micrlhf/gguf.py:47\u001b[0m, in \u001b[0;36mread_gguf\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m GGUFMultiplexer([GGUFReader(f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m filename])\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mGGUFReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micrlhf-progress/micrlhf/gguf.py:78\u001b[0m, in \u001b[0;36mGGUFReader.__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename: os\u001b[38;5;241m.\u001b[39mPathLike):\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgguf_metadata, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgguf_tensors \u001b[38;5;241m=\u001b[39m \u001b[43mread_gguf_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmmap \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmemmap(filename)\n",
      "File \u001b[0;32m~/micrlhf-progress/micrlhf/gguf.py:113\u001b[0m, in \u001b[0;36mread_gguf_info\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_gguf_info\u001b[39m(filename: os\u001b[38;5;241m.\u001b[39mPathLike):\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m gguf:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m gguf\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m8\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGGUF\u001b[39m\u001b[38;5;130;01m\\x03\u001b[39;00m\u001b[38;5;130;01m\\x00\u001b[39;00m\u001b[38;5;130;01m\\x00\u001b[39;00m\u001b[38;5;130;01m\\x00\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    116\u001b[0m         tensor_count \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<Q\u001b[39m\u001b[38;5;124m\"\u001b[39m, gguf\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m8\u001b[39m))[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/gemma-2b.gguf'"
     ]
    }
   ],
   "source": [
    "from micrlhf.llama import LlamaTransformer\n",
    "llama = LlamaTransformer.from_pretrained(\"models/gemma-2b.gguf\", device_map=\"tpu:0\",\n",
    "                                         from_type=\"gemma\",\n",
    "                                        #  load_eager=True\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neverix/.cache/pypoetry/virtualenvs/micrlhf-progress-a058ydGG-py3.12/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"alpindale/gemma-2b\")\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import jax.numpy as jnp\n",
    "# import jax\n",
    "# from micrlhf.llama import LlamaBlock\n",
    "\n",
    "# tokens = tokenizer.encode(\"The quick brown fox jumps over the lazy dog\")\n",
    "# get_resids = llama.select().at_instances_of(LlamaBlock).apply_with_selected_index(lambda i, x:\n",
    "#     pz.nn.Sequential([\n",
    "#         pz.de.TellIntermediate.from_config(tag=f\"resid_pre_{i}\"),\n",
    "#         x\n",
    "#     ])\n",
    "# )\n",
    "# get_resids = pz.de.CollectingSideOutputs.handling(get_resids, tag_predicate=lambda x: x.startswith(\"resid_pre\"))\n",
    "# token_array = jnp.asarray([tokens] * 4)\n",
    "# token_array = jax.device_put(token_array, jax.sharding.NamedSharding(llama.mesh, jax.sharding.PartitionSpec(\"dp\", \"sp\")))\n",
    "# token_array = pz.nx.wrap(token_array, \"batch\", \"seq\")\n",
    "# inputs = llama.inputs.from_basic_segments(token_array)\n",
    "# get_resids(inputs)[1][0].value.unwrap(\"batch\", \"seq\", \"embedding\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7035e457152e4ac1a317bb071aa7aa7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"output_ae244ba0779c4ca19ff00c6faff13d44\"><script> /* penzai.treescope rendering of a Python object (compressed) */ (()=>{ let observer; let lastStep = new Promise((resolve, reject) => { observer = new IntersectionObserver((entries) => { for (const entry of entries) { if (entry.isIntersecting) { resolve(); observer.disconnect(); return; } } }, {rootMargin: \"1000px\"}); }); window.treescope_decompress_enqueue = (encoded, destId) => { const previous = lastStep; const destElt = document.getElementById(destId); lastStep = (async () => { await previous; let blob = new Blob([ Uint8Array.from(atob(encoded), (m) => m.codePointAt(0)) ]); let reader = blob.stream().pipeThrough( new DecompressionStream(\"deflate\") ).pipeThrough( new TextDecoderStream(\"utf-8\") ).getReader(); let parts = []; while (true) { let step = await reader.read(); if (step.done) { break; } parts.push(step.value); } let newElt = document.createElement(\"div\"); newElt.innerHTML = parts.join(\"\"); destElt.parentNode.replaceChild(newElt, destElt); for (let oldScript of newElt.querySelectorAll(\"script\")) { let newScript = document.createElement(\"script\"); newScript.type = oldScript.type; newScript.textContent = oldScript.textContent; oldScript.parentNode.replaceChild(newScript, oldScript); } })(); requestAnimationFrame(() => { observer.observe(destElt); }); } })(); </script><div id=\"compress_html_9b33bad1365649988be8cf1c826f2567\"><script>window.treescope_decompress_enqueue(\"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\", \"compress_html_9b33bad1365649988be8cf1c826f2567\");</script><span style=\"color: #aaaaaa; font-family: monospace\">(Loading...)</span></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"output_dest_ae244ba0779c4ca19ff00c6faff13d44\"><script> (()=>{ const output = document.getElementById(\"output_ae244ba0779c4ca19ff00c6faff13d44\"); const dest = document.getElementById(\"output_dest_ae244ba0779c4ca19ff00c6faff13d44\"); dest.parentNode.replaceChild(output, dest); })(); </script></div>"
      ],
      "text/plain": [
       "[\"<bos>Write me a poem about Machine Learning. Here's what you'll get. Age 2011 a box of light, It makes you wonder All transformed by chance into A computer as blissful as man ..., Why do I need proofs of Me, you and the readers' entrusts? For it can\",\n",
       " '<bos>Write me a poem about Machine Learning.\\n\\nBecause sometimes you have this implicit, implicit relationship between mathematics and computer science that you — at least I am stupid enough to think — you could easily make a machine learning algorithm into a mathematical theory about class.\\n\\nThe same mixed text, a fact found only by realizing that',\n",
       " '<bos>Write me a poem about Machine Learning. about the importance of learning. about the necessary work involved in teaching ourselves to learn in an age of plentiful free and open source knowledge. about the <em>changing</em> nature of \"teaching\" as opposed to teaching <em>in</em>.\\n\\nWrite me a poem about Network Analysis',\n",
       " \"<bos>Write me a poem about Machine Learning.\\n\\nI'll try to keep it straight forward, not bendingly philosophical or uber-complicated, just simple and to the point. Then I'll do what they ask of me and give it to you ;)\\n\\nI was reading through a long stream of news on a\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from micrlhf.sampling import sample\n",
    "sample(llama, tokenizer, \"Write me a poem about Machine Learning.\",\n",
    "       batch_size=4, do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c18653b3bd0343ff855b79794418b13e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"output_898ad242986a43428b5b4fe11208a457\"><script> /* penzai.treescope rendering of a Python object (compressed) */ (()=>{ let observer; let lastStep = new Promise((resolve, reject) => { observer = new IntersectionObserver((entries) => { for (const entry of entries) { if (entry.isIntersecting) { resolve(); observer.disconnect(); return; } } }, {rootMargin: \"1000px\"}); }); window.treescope_decompress_enqueue = (encoded, destId) => { const previous = lastStep; const destElt = document.getElementById(destId); lastStep = (async () => { await previous; let blob = new Blob([ Uint8Array.from(atob(encoded), (m) => m.codePointAt(0)) ]); let reader = blob.stream().pipeThrough( new DecompressionStream(\"deflate\") ).pipeThrough( new TextDecoderStream(\"utf-8\") ).getReader(); let parts = []; while (true) { let step = await reader.read(); if (step.done) { break; } parts.push(step.value); } let newElt = document.createElement(\"div\"); newElt.innerHTML = parts.join(\"\"); destElt.parentNode.replaceChild(newElt, destElt); for (let oldScript of newElt.querySelectorAll(\"script\")) { let newScript = document.createElement(\"script\"); newScript.type = oldScript.type; newScript.textContent = oldScript.textContent; oldScript.parentNode.replaceChild(newScript, oldScript); } })(); requestAnimationFrame(() => { observer.observe(destElt); }); } })(); </script><div id=\"compress_html_9c7a07fcf5eb4206a75d28b3160b1448\"><script>window.treescope_decompress_enqueue(\"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\", \"compress_html_9c7a07fcf5eb4206a75d28b3160b1448\");</script><span style=\"color: #aaaaaa; font-family: monospace\">(Loading...)</span></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"output_dest_898ad242986a43428b5b4fe11208a457\"><script> (()=>{ const output = document.getElementById(\"output_898ad242986a43428b5b4fe11208a457\"); const dest = document.getElementById(\"output_dest_898ad242986a43428b5b4fe11208a457\"); dest.parentNode.replaceChild(output, dest); })(); </script></div>"
      ],
      "text/plain": [
       "[' Maybe don’t make it rhyme or speak in limericks (that just sounds… gauche), but no matter, it’ll probably still be a bit awkward to read out loud that way…\\n\\nIf you honestly cant spell Im not sure you know what Machine Learning is',\n",
       " \"\\nI would like to try creating my own shell like Yoshi's in Mario Bros. 2, but I run into problems when I first enter the map with these commands:\\n\\nhttp://www.hackwithcc.net/content/178/Mario-\"]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample(llama, tokenizer, [\"Write me a poem about Machine Learning.\", \"Hi!\"], do_sample=True, return_only_completion=True, seed=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoModelForCausalLM\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"alpindale/gemma-2b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from collections import OrderedDict\n",
    "# for m in model.modules():\n",
    "#     m._forward_hooks = OrderedDict()\n",
    "# model.model.layers[0].register_forward_hook(lambda self, input, output: print(input[0]))\n",
    "# tt = torch.LongTensor(tokens).unsqueeze(0)\n",
    "# model(tt).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micrlhf-progress-a058ydGG-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
