{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if \"models\" not in os.listdir(\".\"):\n",
    "    os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import penzai\n",
    "from penzai import pz\n",
    "pz.ts.register_as_default()\n",
    "pz.ts.register_autovisualize_magic()\n",
    "pz.enable_interactive_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from micrlhf.llama import LlamaTransformer\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "filename = \"models/phi-3-16.gguf\"\n",
    "llama = LlamaTransformer.from_pretrained(filename, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from micrlhf.sampling import sample, LlamaKVCachingTransformer\n",
    "from micrlhf.utils.activation_manipulation import replace_activation, add_vector\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from micrlhf.llama import LlamaBlock\n",
    "from micrlhf.flash import flashify\n",
    "from micrlhf.sampling import sample, trange, jnp, load_tokenizer, jit_wrapper\n",
    "get_resids = llama.select().at_instances_of(LlamaBlock).apply_with_selected_index(lambda i, x:\n",
    "    pz.nn.Sequential([\n",
    "        pz.de.TellIntermediate.from_config(tag=f\"resid_pre.{i}\"),\n",
    "        x\n",
    "    ])\n",
    ")\n",
    "get_resids = pz.de.CollectingSideOutputs.handling(get_resids, tag_predicate=lambda x: x.startswith(\"resid_pre\"))\n",
    "get_resids_call = jit_wrapper.Jitted(get_resids)\n",
    "def rep_w_linear(mod):\n",
    "    val = mod.table.embeddings.value  # vocabulary, embedding\n",
    "    return pz.nn.Linear(pz.nn.Parameter(val, \"input_embed\"), [\"vocabulary\"], [\"embedding\"])\n",
    "get_resids_one_hot = get_resids.select().at_instances_of(pz.nn.EmbeddingLookup).apply(rep_w_linear)\n",
    "get_resids_one_hot_call = jit_wrapper.Jitted(get_resids_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from micrlhf.sampling import sample, trange, jnp, load_tokenizer, jit_wrapper\n",
    "from tqdm.auto import trange\n",
    "from penzai.toolshed import sharding_util\n",
    "import dataclasses\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import jax\n",
    "\n",
    "@jax.jit\n",
    "def loss_fn(logits, inputs):\n",
    "    losses = pz.nx.nmap(lambda l, i: jnp.take_along_axis(jax.nn.log_softmax(l[:-1], -1), i[1:, None], 1)[:, 0].mean()\n",
    "                        )(logits.untag(\"seq\", \"vocabulary\"), inputs.tokens.untag(\"seq\"))\n",
    "    return -losses\n",
    "\n",
    "bs_start = llama.mesh.shape[\"dp\"]\n",
    "# n_x = 16\n",
    "# n_x = 19\n",
    "# n_x = 20\n",
    "n_x = 32\n",
    "has_end = False\n",
    "tokens_init = tokenizer.encode(f\"<|user|>\\nX{' X' * n_x}\" + (\"<|end|>\\n<|assistant|>\\n\" if has_end else \"\"))\n",
    "optim_mask = [token == 1060 for token in tokens_init]\n",
    "tokens_init = np.asarray(tokens_init)\n",
    "MAX_ELITES = 8\n",
    "PROB_SWAP = 0.1  # probability of a swap\n",
    "PROB_GRADS = 0.8    # probability of using gradients \n",
    "tokens_init = np.repeat(tokens_init[None, :], MAX_ELITES, axis=0)\n",
    "def tokens_to_array(tokens):\n",
    "    token_array = jnp.asarray(tokens)\n",
    "    if len(token_array) >= bs_start:\n",
    "        token_array = jax.device_put(token_array, jax.sharding.NamedSharding(llama.mesh, jax.sharding.PartitionSpec(\"dp\", \"sp\")))\n",
    "    token_array = pz.nx.wrap(token_array, \"batch\", \"seq\")\n",
    "    return token_array\n",
    "def run_tokens(token_array, grad_metric=None):\n",
    "    if not isinstance(token_array, pz.nx.NamedArray):\n",
    "        token_array = tokens_to_array(token_array)\n",
    "    inputs = llama.inputs.from_basic_segments(token_array)\n",
    "    if grad_metric:\n",
    "        @partial(jax.grad, has_aux=True)\n",
    "        def lwg(x):\n",
    "            logits, resids = get_resids_one_hot_call(dataclasses.replace(inputs, tokens=x))\n",
    "            resids = {resid.tag: resid.value for resid in resids}\n",
    "            metric = grad_metric(logits, resids, inputs)\n",
    "            return metric, (logits, resids)\n",
    "        vocab = llama.select().at_instances_of(pz.nn.EmbeddingLookup).get_sequence()[0].table.embeddings.value.named_shape[\"vocabulary\"]\n",
    "        one_hots = pz.nx.nmap(lambda x: jax.nn.one_hot(x, vocab))(inputs.tokens).tag(\"vocabulary\")\n",
    "        grad, (logits, resids) = lwg(one_hots)\n",
    "    else:\n",
    "        logits, resids = get_resids_call(inputs)\n",
    "    losses = loss_fn(logits, inputs)\n",
    "    if not grad_metric:\n",
    "        resids = {resid.tag: resid.value for resid in resids}\n",
    "    return_vals = logits, losses, resids\n",
    "    if grad_metric:\n",
    "        return_vals = return_vals + (grad,)\n",
    "    return return_vals\n",
    "\n",
    "mask = jax.device_put(jnp.asarray(optim_mask), jax.sharding.NamedSharding(llama.mesh, jax.sharding.PartitionSpec(\"sp\")))\n",
    "\n",
    "# @partial(jax.jit, static_argnames=(\"max_inv_temp\", \"expected_changes\"))\n",
    "@jax.jit\n",
    "def temper(logits, key, elites, grads, max_inv_temp, expected_changes):\n",
    "    key_choice, key_random = jax.random.split(key)\n",
    "    index = jax.random.randint(key_choice, (), 0, len(logits) - 1)\n",
    "    key_categorical, key_uniform, key_bernoulli, key_randint, key_use_grads, key_mutations = jax.random.split(key_random, 6)\n",
    "    logit = logits[index]\n",
    "    elite = elites[index]\n",
    "    grads = grads[index]\n",
    "    \n",
    "    logit = jnp.roll(logit, 1, 0)\n",
    "    logit = logit * jax.random.uniform(key_uniform, minval=0, maxval=max_inv_temp)\n",
    "    use_grads = jax.random.bernoulli(key_use_grads, p=PROB_GRADS).astype(jnp.int_)\n",
    "    logit = jax.lax.switch(use_grads, ((lambda x: x), (lambda x: jnp.where(grads, x, -jnp.inf))), logit)\n",
    "    # print(expected_changes - 1)\n",
    "    # print(jnp.maximum)\n",
    "    to_change = jax.random.bernoulli(key_bernoulli, jnp.maximum(.5, expected_changes - 1) / mask.sum(), mask.shape)\n",
    "    definite_indices = jax.random.randint(key_randint, mask.shape[:-1], 0, mask.shape[-1])\n",
    "    definite_mask = jax.nn.one_hot(definite_indices, to_change.shape[-1], dtype=jnp.bool_)\n",
    "    to_change = to_change | definite_mask\n",
    "    changed = jnp.where(mask & to_change,\n",
    "                        jax.random.categorical(key_categorical, logit),\n",
    "                        elite)\n",
    "    \n",
    "    key_swap, key_mutations = jax.random.split(key_mutations)\n",
    "    swap_indices = jax.random.randint(key_swap, (2,), 0, mask.sum())\n",
    "    swap_from, swap_to = jnp.nonzero(mask, size=len(mask))[0][swap_indices]\n",
    "    key_swap, key_mutations = jax.random.split(key_mutations)\n",
    "    do_swap = jax.random.bernoulli(key_swap, p=PROB_SWAP)\n",
    "    swapped = changed.at[swap_from].set(changed[swap_to]).at[swap_to].set(changed[swap_from])\n",
    "    changed = jax.lax.cond(do_swap, lambda x: swapped, lambda x: x, changed)\n",
    "    \n",
    "    # key_delete, key_mutations = jax.random.split(key_mutations)\n",
    "    # delete_index = jax.random.randint(key_delete, (), 0, mask.sum())\n",
    "    # indices = jnp.cumsum(mask)\n",
    "    # indices_base = jnp.arange(len(changed))\n",
    "    # deleted = jnp.where(mask, jnp.where(indices > delete_index, indices_base + 1, indices_base), changed)\n",
    "    # key_delete, key_mutations = jax.random.split(key_mutations)\n",
    "    # do_delete = jax.random.bernoulli(key_delete, p=0.1)\n",
    "    # changed = jax.lax.cond(do_delete, lambda x: deleted, lambda x: x, changed)\n",
    "    \n",
    "    return changed\n",
    "\n",
    "# @partial(jax.jit, static_argnames=(\"key\", \"candidates\", \"expected_changes\"))\n",
    "def algo_iteration(elites, vector, key, candidates=128, seed=13, expected_changes=1.5, max_inv_temp=2, topk=128):\n",
    "    elites = elites.untag(\"solutions\").tag(\"batch\")\n",
    "    logits, _, _, grads = run_tokens(elites, grad_metric=lambda _l, r, _i: (r[key][{\"seq\": -1}].untag(\"embedding\") * vector).sum().data_array.mean())\n",
    "    grads = pz.nx.nmap(lambda x: x >= jax.lax.top_k(x, topk)[0][-1])(grads.untag(\"vocabulary\")).tag(\"vocabulary\")\n",
    "    logits = logits.untag(\"batch\").tag(\"elites\")\n",
    "\n",
    "    tempered_samples = pz.nx.nmap(temper)(\n",
    "        logits.untag(\"elites\", \"seq\", \"vocabulary\"),\n",
    "        pz.nx.wrap(jax.random.split(jax.random.key(seed), candidates), \"batch\"),\n",
    "        elites.untag(\"batch\", \"seq\"),\n",
    "        grads.untag(\"batch\", \"seq\", \"vocabulary\"),\n",
    "        pz.nx.wrap(jnp.array(max_inv_temp)), pz.nx.wrap(jnp.array(expected_changes))).tag(\"seq\")\n",
    "    # tempered_samples = sharding_util.name_to_name_device_put(tempered_samples, llama.mesh, dict(batch=\"dp\", seq=\"sp\"))\n",
    "    _, new_losses, new_resids = run_tokens(tempered_samples)\n",
    "\n",
    "    new_scores = (new_resids[key][{\"seq\": -1}].untag(\"embedding\") * vector).sum().astype(new_losses.dtype)\n",
    "    metrics = pz.nx.nmap(lambda *xs: jnp.stack(xs))(new_losses, new_scores).tag(\"metrics\")\n",
    "    solution_axes = [k for k in tempered_samples.named_shape.keys() if k != \"seq\"]\n",
    "    solutions = tempered_samples.untag(*solution_axes).flatten().tag(\"solutions\").unwrap(\"solutions\", \"seq\")\n",
    "    metrics = metrics.untag(*(k for k in solution_axes if k != \"seq\")).flatten().tag(\"solutions\").unwrap(\"solutions\", \"metrics\")\n",
    "\n",
    "    return solutions, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2024-08-14 19:40:33--  https://huggingface.co/nev/phi-3-4k-saex-test/resolve/main/l20-test-run-5-7.00E-06/sae_weights.safetensors?download=true\n",
      "Resolving huggingface.co (huggingface.co)... 108.156.211.51, 108.156.211.95, 108.156.211.125, ...\n",
      "Connecting to huggingface.co (huggingface.co)|108.156.211.51|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cdn-lfs-us-1.huggingface.co/repos/eb/d8/ebd889d6ac58573e8e8a7aa1176d4d357581a6da60135b94aca378fddf4e9e54/83ac196e9d76d5a3db26b4cc47737ff5c79d3cba0ce3954d02283b9331464948?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27sae_weights.safetensors%3B+filename%3D%22sae_weights.safetensors%22%3B&Expires=1723923633&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyMzkyMzYzM319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2ViL2Q4L2ViZDg4OWQ2YWM1ODU3M2U4ZThhN2FhMTE3NmQ0ZDM1NzU4MWE2ZGE2MDEzNWI5NGFjYTM3OGZkZGY0ZTllNTQvODNhYzE5NmU5ZDc2ZDVhM2RiMjZiNGNjNDc3MzdmZjVjNzlkM2NiYTBjZTM5NTRkMDIyODNiOTMzMTQ2NDk0OD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=ITBYo3mKRphmI1e0ky8xasDce1rgRCGeB2Quvr7ka4PjLXniOUqTXvUEOqZaEHnaXTn061KSM3sQ-ZzlkybZgiIYuPMbz2wYvY1QkHeq91C%7E1Zi5W2VJvbTZUgvQoiPaQ5Isd5sKrywHXA4YWezb7xznSe5c6lgreKhCYxD3lijBWbvr3cAfdGS5GyI7XWUShWhAIRwW4J1jyk2PNFljyNA0q%7EWkHzcaaGJmKW1R4I-NXVBLcHZzK3f54cjI7PjQD4NeQP0WbNgDEbhU6lX0QBKIoCJlRatt3wrElDVVyxNPxyQlChhw3zaUCDQJUdTCeLtI-lQRw5arbV6ZE2mwJQ__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
      "--2024-08-14 19:40:33--  https://cdn-lfs-us-1.huggingface.co/repos/eb/d8/ebd889d6ac58573e8e8a7aa1176d4d357581a6da60135b94aca378fddf4e9e54/83ac196e9d76d5a3db26b4cc47737ff5c79d3cba0ce3954d02283b9331464948?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27sae_weights.safetensors%3B+filename%3D%22sae_weights.safetensors%22%3B&Expires=1723923633&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyMzkyMzYzM319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2ViL2Q4L2ViZDg4OWQ2YWM1ODU3M2U4ZThhN2FhMTE3NmQ0ZDM1NzU4MWE2ZGE2MDEzNWI5NGFjYTM3OGZkZGY0ZTllNTQvODNhYzE5NmU5ZDc2ZDVhM2RiMjZiNGNjNDc3MzdmZjVjNzlkM2NiYTBjZTM5NTRkMDIyODNiOTMzMTQ2NDk0OD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=ITBYo3mKRphmI1e0ky8xasDce1rgRCGeB2Quvr7ka4PjLXniOUqTXvUEOqZaEHnaXTn061KSM3sQ-ZzlkybZgiIYuPMbz2wYvY1QkHeq91C%7E1Zi5W2VJvbTZUgvQoiPaQ5Isd5sKrywHXA4YWezb7xznSe5c6lgreKhCYxD3lijBWbvr3cAfdGS5GyI7XWUShWhAIRwW4J1jyk2PNFljyNA0q%7EWkHzcaaGJmKW1R4I-NXVBLcHZzK3f54cjI7PjQD4NeQP0WbNgDEbhU6lX0QBKIoCJlRatt3wrElDVVyxNPxyQlChhw3zaUCDQJUdTCeLtI-lQRw5arbV6ZE2mwJQ__&Key-Pair-Id=K24J24Z295AEI9\n",
      "Resolving cdn-lfs-us-1.huggingface.co (cdn-lfs-us-1.huggingface.co)... 18.245.124.105, 18.245.124.17, 18.245.124.35, ...\n",
      "Connecting to cdn-lfs-us-1.huggingface.co (cdn-lfs-us-1.huggingface.co)|18.245.124.105|:443... connected.\n",
      "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
      "\n",
      "    The file is already fully retrieved; nothing to do.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from micrlhf.utils.load_sae import get_sae\n",
    "from micrlhf.utils.vector_storage import save_and_upload_vector, download_vector\n",
    "import jax.numpy as jnp\n",
    "layer = 20\n",
    "sae = get_sae(layer, 5)\n",
    "dictionary = sae[\"W_dec\"]\n",
    "# vector = dictionary[27894]\n",
    "# vector = dictionary[15036]\n",
    "vector = dictionary[23629]\n",
    "# layer, vector = 16, download_vector(\"phi-refusal-ablit\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 2120604558\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7de823bbee464a2f92eff816c19c4bb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m best_metrics, best\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m seed \u001b[38;5;129;01min\u001b[39;00m (bar \u001b[38;5;241m:=\u001b[39m trange(\u001b[38;5;241m2_500\u001b[39m)):\n\u001b[0;32m---> 33\u001b[0m     solutions, metrics \u001b[38;5;241m=\u001b[39m \u001b[43malgo_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresid_pre.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlayer\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     best_metrics, best \u001b[38;5;241m=\u001b[39m combine_solutions(best_metrics, best, metrics, solutions)\n\u001b[1;32m     35\u001b[0m     m \u001b[38;5;241m=\u001b[39m {}\n",
      "Cell \u001b[0;32mIn[7], line 106\u001b[0m, in \u001b[0;36malgo_iteration\u001b[0;34m(elites, vector, key, candidates, seed, expected_changes, max_inv_temp, topk)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21malgo_iteration\u001b[39m(elites, vector, key, candidates\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m13\u001b[39m, expected_changes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.5\u001b[39m, max_inv_temp\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, topk\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m):\n\u001b[1;32m    105\u001b[0m     elites \u001b[38;5;241m=\u001b[39m elites\u001b[38;5;241m.\u001b[39muntag(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msolutions\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mtag(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 106\u001b[0m     logits, _, _, grads \u001b[38;5;241m=\u001b[39m \u001b[43mrun_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43melites\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_l\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_i\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muntag\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43membedding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvector\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_array\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     grads \u001b[38;5;241m=\u001b[39m pz\u001b[38;5;241m.\u001b[39mnx\u001b[38;5;241m.\u001b[39mnmap(\u001b[38;5;28;01mlambda\u001b[39;00m x: x \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mlax\u001b[38;5;241m.\u001b[39mtop_k(x, topk)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])(grads\u001b[38;5;241m.\u001b[39muntag(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvocabulary\u001b[39m\u001b[38;5;124m\"\u001b[39m))\u001b[38;5;241m.\u001b[39mtag(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvocabulary\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    108\u001b[0m     logits \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39muntag(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mtag(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melites\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 45\u001b[0m, in \u001b[0;36mrun_tokens\u001b[0;34m(token_array, grad_metric)\u001b[0m\n\u001b[1;32m     43\u001b[0m     metric \u001b[38;5;241m=\u001b[39m grad_metric(logits, resids, inputs)\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m metric, (logits, resids)\n\u001b[0;32m---> 45\u001b[0m vocab \u001b[38;5;241m=\u001b[39m \u001b[43mllama\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mat_instances_of\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbeddingLookup\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mget_sequence()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtable\u001b[38;5;241m.\u001b[39membeddings\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mnamed_shape[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvocabulary\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     46\u001b[0m one_hots \u001b[38;5;241m=\u001b[39m pz\u001b[38;5;241m.\u001b[39mnx\u001b[38;5;241m.\u001b[39mnmap(\u001b[38;5;28;01mlambda\u001b[39;00m x: jax\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mone_hot(x, vocab))(inputs\u001b[38;5;241m.\u001b[39mtokens)\u001b[38;5;241m.\u001b[39mtag(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvocabulary\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     47\u001b[0m grad, (logits, resids) \u001b[38;5;241m=\u001b[39m lwg(one_hots)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/micrlhf-progress-a058ydGG-py3.10/lib/python3.10/site-packages/penzai/core/selectors.py:824\u001b[0m, in \u001b[0;36mSelection.at_instances_of\u001b[0;34m(self, cls, innermost)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mat_instances_of\u001b[39m(\n\u001b[1;32m    803\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    804\u001b[0m     \u001b[38;5;28mcls\u001b[39m: \u001b[38;5;28mtype\u001b[39m[OtherSubtree] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mtype\u001b[39m[OtherSubtree], \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m],\n\u001b[1;32m    805\u001b[0m     innermost: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    806\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSelection[OtherSubtree]\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    807\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Selects subtrees that are an instance of the given type.\u001b[39;00m\n\u001b[1;32m    808\u001b[0m \n\u001b[1;32m    809\u001b[0m \u001b[38;5;124;03m  Convenience wrapper for::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;124;03m    ``innermost=True``), but never both.\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 824\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mat_subtrees_where\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubtree\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubtree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minnermost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minnermost\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/micrlhf-progress-a058ydGG-py3.10/lib/python3.10/site-packages/penzai/core/selectors.py:800\u001b[0m, in \u001b[0;36mSelection.at_subtrees_where\u001b[0;34m(self, filter_fn, with_keypath, absolute_keypath, innermost)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Processes one of the selected subtrees.\"\"\"\u001b[39;00m\n\u001b[1;32m    796\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m jax\u001b[38;5;241m.\u001b[39mtree_util\u001b[38;5;241m.\u001b[39mtree_map(\n\u001b[1;32m    797\u001b[0m       process_leaf_or_filtered, selected_subtree, is_leaf\u001b[38;5;241m=\u001b[39msafe_filter_fn\n\u001b[1;32m    798\u001b[0m   )\n\u001b[0;32m--> 800\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_build_selection_from_boundary\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_selected\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/micrlhf-progress-a058ydGG-py3.10/lib/python3.10/site-packages/penzai/core/selectors.py:1379\u001b[0m, in \u001b[0;36m_build_selection_from_boundary\u001b[0;34m(tree_with_boundary)\u001b[0m\n\u001b[1;32m   1375\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;66;03m# This is just an ordinary leaf; keep it in the remainder.\u001b[39;00m\n\u001b[1;32m   1377\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m leaf\n\u001b[0;32m-> 1379\u001b[0m remainder \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_map_with_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprocess_selected\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtree_with_boundary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_leaf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_is_hole_or_quote\u001b[49m\n\u001b[1;32m   1381\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1382\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Selection(selected_by_path\u001b[38;5;241m=\u001b[39mselected_by_path, remainder\u001b[38;5;241m=\u001b[39mremainder)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/micrlhf-progress-a058ydGG-py3.10/lib/python3.10/site-packages/jax/_src/tree_util.py:1176\u001b[0m, in \u001b[0;36mtree_map_with_path\u001b[0;34m(f, tree, is_leaf, *rest)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;129m@export\u001b[39m\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtree_map_with_path\u001b[39m(f: Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, Any],\n\u001b[1;32m   1149\u001b[0m                        tree: Any, \u001b[38;5;241m*\u001b[39mrest: Any,\n\u001b[1;32m   1150\u001b[0m                        is_leaf: Callable[[Any], \u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1151\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Maps a multi-input function over pytree key path and args to produce a new pytree.\u001b[39;00m\n\u001b[1;32m   1152\u001b[0m \n\u001b[1;32m   1153\u001b[0m \u001b[38;5;124;03m  This is a more powerful alternative of ``tree_map`` that can take the key path\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;124;03m    - :func:`jax.tree_util.tree_leaves_with_path`\u001b[39;00m\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1176\u001b[0m   keypath_leaves, treedef \u001b[38;5;241m=\u001b[39m \u001b[43mtree_flatten_with_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_leaf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1177\u001b[0m   keypath_leaves \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mkeypath_leaves))\n\u001b[1;32m   1178\u001b[0m   all_keypath_leaves \u001b[38;5;241m=\u001b[39m keypath_leaves \u001b[38;5;241m+\u001b[39m [treedef\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rest]\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/micrlhf-progress-a058ydGG-py3.10/lib/python3.10/site-packages/jax/_src/tree_util.py:1082\u001b[0m, in \u001b[0;36mtree_flatten_with_path\u001b[0;34m(tree, is_leaf)\u001b[0m\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;129m@export\u001b[39m\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtree_flatten_with_path\u001b[39m(\n\u001b[1;32m   1070\u001b[0m     tree: Any, is_leaf: Callable[[Any], \u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1071\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[KeyPath, Any]], PyTreeDef]:\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Flattens a pytree like ``tree_flatten``, but also returns each leaf's key path.\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m \n\u001b[1;32m   1074\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[38;5;124;03m    representing the structure of the flattened tree.\u001b[39;00m\n\u001b[1;32m   1081\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1082\u001b[0m   _, tree_def \u001b[38;5;241m=\u001b[39m \u001b[43mtree_flatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_leaf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1083\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _generate_key_paths(tree, is_leaf), tree_def\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/micrlhf-progress-a058ydGG-py3.10/lib/python3.10/site-packages/jax/_src/tree_util.py:78\u001b[0m, in \u001b[0;36mtree_flatten\u001b[0;34m(tree, is_leaf)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;129m@export\u001b[39m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtree_flatten\u001b[39m(tree: Any,\n\u001b[1;32m     75\u001b[0m                  is_leaf: Callable[[Any], \u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     76\u001b[0m                  ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mlist\u001b[39m[Leaf], PyTreeDef]:\n\u001b[1;32m     77\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Alias of :func:`jax.tree.flatten`.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdefault_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_leaf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/micrlhf-progress-a058ydGG-py3.10/lib/python3.10/site-packages/penzai/core/struct.py:621\u001b[0m, in \u001b[0;36mStruct.tree_flatten\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    619\u001b[0m static_fields \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    620\u001b[0m \u001b[38;5;66;03m# `self` is guaranteed to be a dataclass by AbstractStructMetaclass\u001b[39;00m\n\u001b[0;32m--> 621\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m field_ \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdataclasses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m:  \u001b[38;5;66;03m# pytype: disable=wrong-arg-types\u001b[39;00m\n\u001b[1;32m    622\u001b[0m   value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, field_\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m    623\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_pytree_node_field(field_):\n",
      "File \u001b[0;32m/usr/lib/python3.10/dataclasses.py:1203\u001b[0m, in \u001b[0;36mfields\u001b[0;34m(class_or_instance)\u001b[0m\n\u001b[1;32m   1199\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmust be called with a dataclass type or instance\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;66;03m# Exclude pseudo-fields.  Note that fields is sorted by insertion\u001b[39;00m\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;66;03m# order, so the order of the tuple is as the fields were defined.\u001b[39;00m\n\u001b[0;32m-> 1203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fields\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39m_field_type \u001b[38;5;129;01mis\u001b[39;00m _FIELD)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "seed = random.randint(0, 2**32-1)\n",
    "print(\"Seed:\", seed)\n",
    "np.random.seed(seed)\n",
    "toks_init = tokens_init.copy()\n",
    "toks_init[:, optim_mask] = np.random.randint(100, tokenizer.vocab_size, toks_init[:, optim_mask].shape)\n",
    "best_metrics = None\n",
    "best = tokens_to_array(toks_init).untag(\"batch\").tag(\"solutions\")\n",
    "xent_min = 1\n",
    "xent_max = 10\n",
    "weights = jnp.stack((\n",
    "    -jnp.exp(jnp.linspace(jnp.log(xent_min), jnp.log(xent_max), MAX_ELITES))[::-1],\n",
    "    jnp.ones(MAX_ELITES),\n",
    "), -1)\n",
    "@partial(jax.jit, donate_argnums=(0, 1))\n",
    "def combine_solutions(best_metrics, best, metrics, solutions):\n",
    "    if best_metrics is not None:\n",
    "        best_metrics = jnp.concatenate((best_metrics, metrics), 0)\n",
    "        best = pz.nx.nmap(lambda a, b: jnp.concatenate((a, b)))(\n",
    "            best.untag(\"solutions\"),\n",
    "            pz.nx.wrap(solutions, \"solutions\", \"seq\").untag(\"solutions\")\n",
    "        ).tag(\"solutions\").unwrap(\"solutions\", \"seq\")\n",
    "    else:\n",
    "        best_metrics = metrics\n",
    "        best = solutions\n",
    "    elite_mask = (best_metrics[None, :] * weights[:, None]).sum(-1).argmax(1)\n",
    "    best_metrics = best_metrics[elite_mask]\n",
    "    best = pz.nx.wrap(best[elite_mask], \"solutions\", \"seq\")\n",
    "    return best_metrics, best\n",
    "for seed in (bar := trange(2_500)):\n",
    "    solutions, metrics = algo_iteration(best, vector, seed=seed, key=f\"resid_pre.{layer}\")\n",
    "    best_metrics, best = combine_solutions(best_metrics, best, metrics, solutions)\n",
    "    m = {}\n",
    "    for index in range(MAX_ELITES):\n",
    "        i = index\n",
    "        m |= {f\"decoded.{i}\": tokenizer.decode(best[{\"solutions\": index}].unwrap(\"seq\")),\n",
    "              f\"loss.{i}\": best_metrics[index][0], f\"score.{i}\": best_metrics[index][1]}\n",
    "    bar.set_postfix(**m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micrlhf-progress-a058ydGG-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
