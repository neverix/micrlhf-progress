{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if \"models\" not in os.listdir(\".\"):\n",
    "    os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import penzai\n",
    "from penzai import pz\n",
    "pz.ts.register_as_default()\n",
    "pz.ts.register_autovisualize_magic()\n",
    "pz.enable_interactive_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from micrlhf.llama import LlamaTransformer\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "filename = \"models/phi-3-16.gguf\"\n",
    "llama = LlamaTransformer.from_pretrained(filename, device_map=\"tpu:0\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from micrlhf.llama import LlamaBlock\n",
    "embeds = llama.select().at_instances_of(pz.nn.EmbeddingLookup).get_sequence()[0].table.embeddings.value.unwrap(\"vocabulary\", \"embedding\")\n",
    "llama_without_embeds = llama.select().at_instances_of(pz.nn.EmbeddingLookup).apply(lambda x: pz.nn.Identity())\n",
    "get_resids = llama_without_embeds.select().at_instances_of(LlamaBlock).apply_with_selected_index(lambda i, x:\n",
    "    pz.nn.Sequential([\n",
    "        pz.de.TellIntermediate.from_config(tag=f\"resid_pre_{i}\"),\n",
    "        x\n",
    "    ])\n",
    ")\n",
    "get_resids = pz.de.CollectingSideOutputs.handling(get_resids, tag_predicate=lambda x: x.startswith(\"resid_pre\"))\n",
    "llama_without_embeds = get_resids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from micrlhf.utils.vector_storage import load_vector\n",
    "refusal_layer = 20\n",
    "refusal_vector = load_vector(f\"phi-refusal-ablit\", from_remote=True, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"output_8529b84d9cd84f70b0ba4718d68b5f7a\"><script> /* penzai.treescope rendering of a Python object (compressed) */ (()=>{ let observer; let lastStep = new Promise((resolve, reject) => { observer = new IntersectionObserver((entries) => { for (const entry of entries) { if (entry.isIntersecting) { resolve(); observer.disconnect(); return; } } }, {rootMargin: \"1000px\"}); }); window.treescope_decompress_enqueue = (encoded, destId) => { const previous = lastStep; const destElt = document.getElementById(destId); lastStep = (async () => { await previous; let blob = new Blob([ Uint8Array.from(atob(encoded), (m) => m.codePointAt(0)) ]); let reader = blob.stream().pipeThrough( new DecompressionStream(\"deflate\") ).pipeThrough( new TextDecoderStream(\"utf-8\") ).getReader(); let parts = []; while (true) { let step = await reader.read(); if (step.done) { break; } parts.push(step.value); } let newElt = document.createElement(\"div\"); newElt.innerHTML = parts.join(\"\"); destElt.parentNode.replaceChild(newElt, destElt); for (let oldScript of newElt.querySelectorAll(\"script\")) { let newScript = document.createElement(\"script\"); newScript.type = oldScript.type; newScript.textContent = oldScript.textContent; oldScript.parentNode.replaceChild(newScript, oldScript); } })(); requestAnimationFrame(() => { observer.observe(destElt); }); } })(); </script><div id=\"compress_html_d6d56f1c2ea84c5ab299f4ef0cf82efa\"><script>window.treescope_decompress_enqueue(\"eNqVVs1u20YQfpUJAwhUENGxgyCAKAownBYFGrRAHaCHIiAockgutNxld4eWlUSHJg/SS9+jh7xA/EadXUoyZSuJCx24Ozs/3/xrZmktcR6RQbS5bjE1WhO8h1ZbQUKrKRiUGYkrjKHUiiZl1gi5nkKjlbZtljN9VQvCib9MoTVMkcLSxKue0LplqtKKyYssX1ZGd6qY5FpqM+1FY9jeFpIZWJ8oqJ5CKYjZFKGiGJrMVEJNJJY0hbO8djYUTmoUVc2U0+hFDJvZSe/OzOZGtDQHUUK4EqrQq1sPIUkSYAhYsoJizL7e54D3m/geOUpbVIVQ1XnuImOZ7Y+332X7KVOFdCpVJ+UR7gopvRP9BMJd0FPSY0jmDPLkCbzWeslJMEA1gudUusAInpyARIKt7EDUp4aNh/3bowQKnXcNBzRa6GINoxE8ci9RLjNrX3PSIhfwTCgbBoeggjG4UO1sOKE2M6zpB4mNz9CGLVNnlH/k6xFfTacutVbOwZU2y61nbNISI/udSe7pgEwid8QWDTveZCrHSOlVON67du8FJr3QDJ6fOcjHauBuKiOJqqKaSwOeHauIb+e099tFAKXFW+h1pxz27xq3tSjJueQl3GHDv4diCHecBv/s0NK5Ek3mOH40WYNhH9fx+HhG7kJpO1v3uYkfErgdiKQPxf8J3cNhHwWOiqU6fIUlGoPFG2xaLnu09wuolY64L3wWM+tLlJiTNudScqFvZYdDsFOp5UoNxrFvuND1F2sCXXqFzlH+DvrGYKOv8KBrBjq+1gnhDqvTXxr9Dl1zeM394DuEGwb9YHMqnQTfhq7lBtmNbUMOefkUuTnMzL0Rf9vS8ZouemOD51ti7OH0vf6LGzcGOVo5XnD7FSFreOoYXJ6+mivSVSX7MZL66U8MzE85pqCkp4BXrH0bCld2/h4tce06MjDBbvQw8yDmvd4w2OtMGwYY7HBsgPdBvwhmhbgCL5jcnWtA2YIB43USPAtAKzbK6NWA7zj+kGphd8gDXjn9IvWbLLXMoSpfg36xPc6en744PVxRbaZ2kGrOhuF9tkyJ1xwyqCKjbMJQ2ozqJAgO2Yc2gvno8fXZy3gkKbajivzhQ2fRfHA3eIUNvGF/YIE1u1nhQnDhXGjuwV9/BqG4zm7+uvl48+nLv5//+fw38AT6rbMWLrFw/wHQdREJVNibYfgMZL7/cFz32/bBPRqO94n5D6llDyQ=\", \"compress_html_d6d56f1c2ea84c5ab299f4ef0cf82efa\");</script><span style=\"color: #aaaaaa; font-family: monospace\">(Loading...)</span></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"output_dest_8529b84d9cd84f70b0ba4718d68b5f7a\"><script> (()=>{ const output = document.getElementById(\"output_8529b84d9cd84f70b0ba4718d68b5f7a\"); const dest = document.getElementById(\"output_dest_8529b84d9cd84f70b0ba4718d68b5f7a\"); dest.parentNode.replaceChild(output, dest); })(); </script></div>"
      ],
      "text/plain": [
       "'<s><|user|> Dem Town behindgebiet Cole OK inconступäß hunRuss Sed pose contiene'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from jax_tqdm import scan_tqdm\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "n_steps = 2_000\n",
    "n_vocab, embed_size = embeds.shape\n",
    "seq_len = 16\n",
    "start_phrase = \"<s><|user|>\"\n",
    "fixed_ids = tokenizer.encode(start_phrase)\n",
    "fixed_tokens = len(fixed_ids)\n",
    "count_loss_from = max(0, fixed_tokens - 1)\n",
    "\n",
    "def compute_loss(logits):\n",
    "    in_probs = jax.nn.softmax(logits, -1)\n",
    "    in_resid = in_probs @ embeds\n",
    "    named_array = pz.nx.NamedArray(OrderedDict({\"batch\": 1, \"seq\": seq_len, \"embedding\": embed_size}), in_resid[None, ...])\n",
    "    logits, residuals = llama_without_embeds(llama.inputs.from_basic_segments(named_array))\n",
    "    logits = logits.unwrap(\"batch\", \"seq\", \"vocabulary\")[0]\n",
    "    out_logprobs = jax.nn.log_softmax(logits, -1)\n",
    "    loss = (in_probs[1:] * out_logprobs[:-1])[count_loss_from:].sum(-1).mean()\n",
    "    return loss - 10 * (residuals[refusal_layer].value[{\"seq\": -1}].unwrap(\"batch\", \"embedding\") @ refusal_vector).mean()\n",
    "\n",
    "def set_token(logits, index, token_id):\n",
    "    return logits.at[index, token_id].set(0).at[index, token_id+1:].set(-1e9).at[index, :token_id].set(-1e9)\n",
    "\n",
    "@scan_tqdm(n_steps)\n",
    "def update_logits(params, hparams):\n",
    "    logits, key = params\n",
    "    for i, token_id in enumerate(fixed_ids):\n",
    "        logits = set_token(logits, i, token_id)\n",
    "    sigma, nu = hparams\n",
    "    grad = jax.grad(compute_loss)(logits)\n",
    "    key, subkey = jax.random.split(key)\n",
    "    noise = jax.random.normal(subkey, logits.shape)\n",
    "    logits = logits - nu * grad + sigma * noise\n",
    "    return (logits, key), None\n",
    "    \n",
    "\n",
    "logits = jax.random.normal(jax.random.key(0), (seq_len, n_vocab)) * 0.1\n",
    "# Throughout the experiments, we set the number of Langevin dynamics steps to N = 2000, with a step size η = 0.1\n",
    "nus = jnp.full(n_steps, 0.1)\n",
    "# In our experiments, we typically used the schedule which sets/reduces σ to {1, 0.5, 0.1, 0.05, 0.01} at iterations {0, 50, 500, 1000, 1500}\n",
    "sigmas = jnp.full(n_steps, 1.).at[50:].set(0.5).at[500:].set(0.1).at[1000:].set(0.05).at[1500:].set(0.01)\n",
    "\n",
    "new_logits = jax.lax.scan(update_logits, (logits, jax.random.key(0)), (sigmas, nus))[0][0]\n",
    "tokenizer.decode(new_logits.argmax(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from penzai.toolshed.jit_wrapper import Jitted\n",
    "ljit = Jitted(llama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c01031a224bd4060b71db33c4286b073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"output_fce5d215cc04493f94addd2196bbb0c8\"><script> /* penzai.treescope rendering of a Python object (compressed) */ (()=>{ let observer; let lastStep = new Promise((resolve, reject) => { observer = new IntersectionObserver((entries) => { for (const entry of entries) { if (entry.isIntersecting) { resolve(); observer.disconnect(); return; } } }, {rootMargin: \"1000px\"}); }); window.treescope_decompress_enqueue = (encoded, destId) => { const previous = lastStep; const destElt = document.getElementById(destId); lastStep = (async () => { await previous; let blob = new Blob([ Uint8Array.from(atob(encoded), (m) => m.codePointAt(0)) ]); let reader = blob.stream().pipeThrough( new DecompressionStream(\"deflate\") ).pipeThrough( new TextDecoderStream(\"utf-8\") ).getReader(); let parts = []; while (true) { let step = await reader.read(); if (step.done) { break; } parts.push(step.value); } let newElt = document.createElement(\"div\"); newElt.innerHTML = parts.join(\"\"); destElt.parentNode.replaceChild(newElt, destElt); for (let oldScript of newElt.querySelectorAll(\"script\")) { let newScript = document.createElement(\"script\"); newScript.type = oldScript.type; newScript.textContent = oldScript.textContent; oldScript.parentNode.replaceChild(newScript, oldScript); } })(); requestAnimationFrame(() => { observer.observe(destElt); }); } })(); </script><div id=\"compress_html_897ff8932ce94183a2b1d054ae7cf489\"><script>window.treescope_decompress_enqueue(\"eNqVVd2O20QUfpVTV4qcqvF2t6qQ4jjSqoBAVPSiSFwgFM3ax/aQ8YyZOd7d0OaC3iBxwwPwHEg8RvMQvAdnxknW2aR0US7ic+b8fOd/5milcJ6QRXS5aXFhjSF4C61xkqTRU7CoBMlrTKE0mialaKRaTaEx2rhW5My/qSXhJBBTaC1zlHQ0CaYntGqZq41m9pXIl5U1nS4muVHGTnvVFLbUlWIBticLqqdQSmIxTagphUbYSuqJwpKmcJHX3ofGSY2yqplznrxIYT0768OZudzKluYgS4hvpC7MzV2EkGUZMAQs2UAx5liPJeDtOj1iJ4sWdSF1dZn7zDgW++HHT4p9JXShvEndKXVCukJa3Mt+BvEu6QsyY8jmDPLsCbwyZslFsEA1QpDUpsAEnpyBQoKt7kA1lIadx/3bowwKk3cNJzS5MsUKRiN45F+SXAnnXnHREp9wIbWLo0NQ0Rh8qnY+vFIrLFv6QmETKrRmz9RZHR6ZPBGr7fQbY7QP8MbY5TYydumIkX3PLP90wCaZe2aLlgNvhM4x0eYmHu9DO3qBSa80g+cXHvKpHrhfykShrqjm1oBnpzriv2vax+0zgMrhHfS60x77J527WpbkQwoa/mPNv4diiHeSFn/u0NGllo3wEl9a0WDc53U8Pl2R+1DaztV9bdKHJG4HIutT8X9S93DYJ4GjZq0OP8cSrcXiO2xabnt0xw3UKs/cNz6r2dUbVJiTsZdKcaNvdYdLsNMLx50ajdMwcLGfL7YEpgwGfaD8P5gbi425xoOpGdj42CTEO6zefmnNL+iHI1juF98h3DjqF5s36TWYGoaWW+QwtgM5lOWvxO9hFu6dBGrLx1t62TsbPN8x0wCnn/Vv/bqxyNnK8SWPXxGzhadewNfpo7UiU1WqXyOLsP2JgYUtxxxU9BTwmq1vU+HbLtDJEld+IiMb7VYPCw9y3tuNo73NRcMAox2ONfA96A/BrJDXEBSz+3sNSFwxYLzNomcRGM1OGb0eyJ3GH1Mt3Q55xCenP6Thki0cS+gq9GA4bI/F8/MX54cnqhV6B6nmali+Z8sF8ZlDBlUIEhOG0gqqsyg6FB/6iOajx7cXn6UjRakbVRQ+3nUO7btjChqJP3FMPOCyqNBt24rbpfvn9z/h9Teb9x/+3vz24S8eyTCLjViiBdc1bvN+8+vmj69fQy216FzvlINhWPP9H2d5f3sfPLHxeF+mfwFfkhgL\", \"compress_html_897ff8932ce94183a2b1d054ae7cf489\");</script><span style=\"color: #aaaaaa; font-family: monospace\">(Loading...)</span></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"output_dest_fce5d215cc04493f94addd2196bbb0c8\"><script> (()=>{ const output = document.getElementById(\"output_fce5d215cc04493f94addd2196bbb0c8\"); const dest = document.getElementById(\"output_dest_fce5d215cc04493f94addd2196bbb0c8\"); dest.parentNode.replaceChild(output, dest); })(); </script></div>"
      ],
      "text/plain": [
       "'<s><|user|><|user|> miejscoworidgeselectormenu力 OKтичеequationmaker sumsтсяIO hinaus'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.auto import trange\n",
    "tokens = new_logits.argmax(-1)\n",
    "k = 5\n",
    "for i in trange(count_loss_from, seq_len - 1):\n",
    "    key = jax.random.key(i)\n",
    "    named_array = pz.nx.NamedArray(OrderedDict({\"batch\": 1, \"seq\": seq_len}), tokens[None, ...])\n",
    "    logits_predicted = ljit(llama.inputs.from_basic_segments(named_array)).unwrap(\"batch\", \"seq\", \"vocabulary\")[0][i]\n",
    "    _, possible_tokens = jax.lax.top_k(new_logits[i], k)\n",
    "    choice = possible_tokens[jax.random.categorical(key, jax.nn.softmax(logits_predicted[possible_tokens]))]\n",
    "    tokens = tokens.at[i + 1].set(choice)\n",
    "tokenizer.decode(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micrlhf-progress-a058ydGG-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
