{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if \"models\" not in os.listdir(\".\"):\n",
    "    os.chdir(\"../..\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from penzai import pz\n",
    "import json\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm, trange\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import random\n",
    "from penzai.data_effects.side_output import SideOutputValue\n",
    "from micrlhf.utils.activation_manipulation import add_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unable to initialize backend 'tpu': ABORTED: The TPU is already in use by process with pid 1484045. Not attempting to load libtpu.so in this process. (set JAX_PLATFORMS='' to automatically choose an available backend)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXlaRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/micrlhf-progress-_SD4q1c9-py3.10/lib/python3.10/site-packages/jax/_src/xla_bridge.py:887\u001b[0m, in \u001b[0;36mbackends\u001b[0;34m()\u001b[0m\n\u001b[1;32m    885\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 887\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[43m_init_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplatform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    888\u001b[0m _backends[platform] \u001b[38;5;241m=\u001b[39m backend\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/micrlhf-progress-_SD4q1c9-py3.10/lib/python3.10/site-packages/jax/_src/xla_bridge.py:973\u001b[0m, in \u001b[0;36m_init_backend\u001b[0;34m(platform)\u001b[0m\n\u001b[1;32m    972\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitializing backend \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m, platform)\n\u001b[0;32m--> 973\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[43mregistration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;66;03m# TODO(skye): consider raising more descriptive errors directly from backend\u001b[39;00m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;66;03m# factories instead of returning None.\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/micrlhf-progress-_SD4q1c9-py3.10/lib/python3.10/site-packages/jax/_src/xla_bridge.py:146\u001b[0m, in \u001b[0;36mtpu_client_timer_callback\u001b[0;34m(timer_secs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m   client \u001b[38;5;241m=\u001b[39m \u001b[43mxla_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_tpu_client\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m      \u001b[49m\u001b[43mget_tpu_library_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_options_from_jax_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/micrlhf-progress-_SD4q1c9-py3.10/lib/python3.10/site-packages/jaxlib/xla_client.py:210\u001b[0m, in \u001b[0;36mmake_tpu_client\u001b[0;34m(library_path, options)\u001b[0m\n\u001b[1;32m    209\u001b[0m   profiler\u001b[38;5;241m.\u001b[39mregister_plugin_profiler(c_api)\n\u001b[0;32m--> 210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmake_tfrt_tpu_c_api_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/micrlhf-progress-_SD4q1c9-py3.10/lib/python3.10/site-packages/jaxlib/xla_client.py:129\u001b[0m, in \u001b[0;36mmake_tfrt_tpu_c_api_client\u001b[0;34m(options)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pjrt_plugin_initialized(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtpu\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 129\u001b[0m   \u001b[43minitialize_pjrt_plugin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m options \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/micrlhf-progress-_SD4q1c9-py3.10/lib/python3.10/site-packages/jaxlib/xla_client.py:177\u001b[0m, in \u001b[0;36minitialize_pjrt_plugin\u001b[0;34m(plugin_name)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Initializes a PJRT plugin.\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03mThe plugin needs to be loaded first (through load_pjrt_plugin_dynamically or\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;124;03m  plugin_name: the name of the PJRT plugin.\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m \u001b[43m_xla\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize_pjrt_plugin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplugin_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mXlaRuntimeError\u001b[0m: ABORTED: The TPU is already in use by process with pid 1484045. Not attempting to load libtpu.so in this process.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmicrlhf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllama\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LlamaTransformer\n\u001b[0;32m----> 2\u001b[0m llama \u001b[38;5;241m=\u001b[39m \u001b[43mLlamaTransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels/gemma-2-2b-it.gguf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mfrom_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgemma2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mload_eager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micrlhf-progress/micrlhf/llama.py:389\u001b[0m, in \u001b[0;36mLlamaTransformer.from_pretrained\u001b[0;34m(cls, gguf_path, from_type, device_map, extract_layer, load_eager, transpose_rotary, load_on_cpu)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pretrained\u001b[39m(\u001b[38;5;28mcls\u001b[39m, gguf_path: os\u001b[38;5;241m.\u001b[39mPathLike \u001b[38;5;241m|\u001b[39m Iterable[os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[1;32m    383\u001b[0m                     from_type: Literal[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemma\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    387\u001b[0m                     load_on_cpu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    388\u001b[0m                     ):\n\u001b[0;32m--> 389\u001b[0m     mesh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_mesh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    391\u001b[0m     gguf \u001b[38;5;241m=\u001b[39m read_gguf(gguf_path)\n\u001b[1;32m    392\u001b[0m     is_gemma \u001b[38;5;241m=\u001b[39m (from_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m from_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemma\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/micrlhf-progress/micrlhf/llama.py:373\u001b[0m, in \u001b[0;36mLlamaTransformer.make_mesh\u001b[0;34m(cls, device_map)\u001b[0m\n\u001b[1;32m    371\u001b[0m             mp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(part\u001b[38;5;241m.\u001b[39mpartition(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m    372\u001b[0m         \u001b[38;5;66;03m# TODO SP support\u001b[39;00m\n\u001b[0;32m--> 373\u001b[0m     mesh \u001b[38;5;241m=\u001b[39m jshard\u001b[38;5;241m.\u001b[39mMesh(np\u001b[38;5;241m.\u001b[39masarray(\u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, mp)), axis_names\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmp\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m device_map\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtpu:\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    375\u001b[0m     tpu_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(device_map\u001b[38;5;241m.\u001b[39mpartition(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/micrlhf-progress-_SD4q1c9-py3.10/lib/python3.10/site-packages/jax/_src/xla_bridge.py:1085\u001b[0m, in \u001b[0;36mdevices\u001b[0;34m(backend)\u001b[0m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdevices\u001b[39m(\n\u001b[1;32m   1061\u001b[0m     backend: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m xla_client\u001b[38;5;241m.\u001b[39mClient \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[xla_client\u001b[38;5;241m.\u001b[39mDevice]:\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a list of all devices for a given backend.\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m \n\u001b[1;32m   1065\u001b[0m \u001b[38;5;124;03m  .. currentmodule:: jaxlib.xla_extension\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1083\u001b[0m \u001b[38;5;124;03m    List of Device subclasses.\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdevices()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/micrlhf-progress-_SD4q1c9-py3.10/lib/python3.10/site-packages/jax/_src/xla_bridge.py:1019\u001b[0m, in \u001b[0;36mget_backend\u001b[0;34m(platform)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;129m@lru_cache\u001b[39m(maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# don't use util.memoize because there is no X64 dependence.\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_backend\u001b[39m(\n\u001b[1;32m   1017\u001b[0m     platform: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m xla_client\u001b[38;5;241m.\u001b[39mClient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m xla_client\u001b[38;5;241m.\u001b[39mClient:\n\u001b[0;32m-> 1019\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_backend_uncached\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplatform\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/micrlhf-progress-_SD4q1c9-py3.10/lib/python3.10/site-packages/jax/_src/xla_bridge.py:998\u001b[0m, in \u001b[0;36m_get_backend_uncached\u001b[0;34m(platform)\u001b[0m\n\u001b[1;32m    994\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m platform\n\u001b[1;32m    996\u001b[0m platform \u001b[38;5;241m=\u001b[39m (platform \u001b[38;5;129;01mor\u001b[39;00m _XLA_BACKEND\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mor\u001b[39;00m _PLATFORM_NAME\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 998\u001b[0m bs \u001b[38;5;241m=\u001b[39m \u001b[43mbackends\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    999\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m platform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1000\u001b[0m   platform \u001b[38;5;241m=\u001b[39m canonicalize_platform(platform)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/micrlhf-progress-_SD4q1c9-py3.10/lib/python3.10/site-packages/jax/_src/xla_bridge.py:903\u001b[0m, in \u001b[0;36mbackends\u001b[0;34m()\u001b[0m\n\u001b[1;32m    901\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    902\u001b[0m         err_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (you may need to uninstall the failing plugin package, or set JAX_PLATFORMS=cpu to skip this backend.)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 903\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(err_msg)\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m _default_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_platforms\u001b[38;5;241m.\u001b[39mvalue:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unable to initialize backend 'tpu': ABORTED: The TPU is already in use by process with pid 1484045. Not attempting to load libtpu.so in this process. (set JAX_PLATFORMS='' to automatically choose an available backend)"
     ]
    }
   ],
   "source": [
    "from micrlhf.llama import LlamaTransformer\n",
    "llama = LlamaTransformer.from_pretrained(\"models/gemma-2-2b-it.gguf\",\n",
    "                                         from_type=\"gemma2\",\n",
    "                                         load_eager=True\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import jax\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"alpindale/gemma-2b\")\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sprint.task_vector_utils import load_tasks, ICLDataset, ICLSequence\n",
    "tasks = load_tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, numpy as np\n",
    "\n",
    "with open(\"cleanup_results_gemma_2_algo.jsonl\", \"r\") as f:\n",
    "    cleanup_results = [json.loads(line) for line in f]\n",
    "\n",
    "\n",
    "with open(\"cleanup_results_gemma_2_all.jsonl\", \"r\") as f:\n",
    "    tmp = [json.loads(line) for line in f]\n",
    "    tmp = [x for x in tmp if not x[\"task\"].startswith(\"algo\")]\n",
    "\n",
    "    cleanup_results += tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n"
     ]
    }
   ],
   "source": [
    "task = \"algo_last\"\n",
    "layers = [14, 16, 18, 20, 22]\n",
    "\n",
    "task_results = [result for result in cleanup_results if result[\"layer\"] in layers]\n",
    "\n",
    "print(len(task_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from micrlhf.utils.load_sae import sae_encode, get_dm_res_sae\n",
    "\n",
    "thresholds = {\n",
    "    layer: get_dm_res_sae(layer).get(\"threshold\", 0) for layer in layers\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'task': 'algo_last', 'weights': [56.39113998413086, 42.13969039916992, 30.260478973388672, 14.489788055419922, 5.450676918029785], 'indices': [11265, 6304, 5088, 8060, 6247], 'tv loss': 1.921875, 'cleaning loss': 0.2197265625, 'ito loss': 2.0, 'layer': 14}\n",
      "{'task': 'algo_last', 'weights': [50.45500564575195, 45.987667083740234, 40.501956939697266, 22.649768829345703], 'indices': [5637, 1160, 9343, 3969], 'tv loss': 0.99609375, 'cleaning loss': 0.2060546875, 'ito loss': 0.55859375, 'layer': 16}\n",
      "{'task': 'algo_last', 'weights': [47.48284149169922, 40.43308639526367, 33.862640380859375, 31.790987014770508], 'indices': [11687, 1255, 14456, 14772], 'tv loss': 2.15625, 'cleaning loss': 0.234375, 'ito loss': 0.4375, 'layer': 18}\n",
      "{'task': 'algo_last', 'weights': [64.82637786865234, 53.81707000732422, 47.99002456665039, 44.49906921386719, 38.31149673461914, 28.91067886352539, 20.28519058227539, 12.863045692443848, 8.231931686401367], 'indices': [5081, 5328, 7445, 9356, 12492, 6814, 2977, 16206, 16060], 'tv loss': 4.125, 'cleaning loss': 0.52734375, 'ito loss': 1.53125, 'layer': 20}\n",
      "{'task': 'algo_last', 'weights': [83.01758575439453, 82.71916198730469, 78.14096069335938, 44.224586486816406, 43.9622688293457, 27.059589385986328], 'indices': [15526, 6951, 16336, 1110, 11202, 5135], 'tv loss': 5.5625, 'cleaning loss': 0.89453125, 'ito loss': 2.296875, 'layer': 22}\n",
      "{'task': 'algo_first', 'weights': [72.8683853149414, 54.90558624267578, 24.836706161499023, 19.843547821044922, 14.987834930419922, 13.646162986755371, 13.50162410736084], 'indices': [13143, 3500, 1029, 12466, 6304, 8610, 11761], 'tv loss': 3.390625, 'cleaning loss': 0.6875, 'ito loss': 3.015625, 'layer': 14}\n",
      "{'task': 'algo_first', 'weights': [41.34523010253906, 40.19194030761719, 32.876129150390625, 19.64117431640625, 11.897354125976562], 'indices': [10140, 5637, 14572, 1281, 14904], 'tv loss': 0.8125, 'cleaning loss': 0.59765625, 'ito loss': 1.421875, 'layer': 16}\n",
      "{'task': 'algo_first', 'weights': [44.22963333129883, 33.74424743652344, 25.090206146240234, 22.89507293701172, 19.671295166015625, 19.221284866333008, 17.41403579711914, 13.604843139648438, 5.905035018920898], 'indices': [13880, 12865, 15887, 1742, 5966, 6607, 1882, 3383, 15992], 'tv loss': 1.828125, 'cleaning loss': 0.66015625, 'ito loss': 2.1875, 'layer': 18}\n",
      "{'task': 'algo_first', 'weights': [84.02973937988281, 66.17730712890625, 52.4997673034668, 47.81617736816406, 40.202518463134766, 36.89754104614258, 15.659363746643066, 6.44309663772583], 'indices': [5328, 2506, 13289, 7445, 9356, 7670, 10388, 11228], 'tv loss': 4.0, 'cleaning loss': 0.859375, 'ito loss': 2.828125, 'layer': 20}\n",
      "{'task': 'algo_first', 'weights': [84.00162506103516, 83.9078598022461, 82.89532470703125, 72.31031036376953], 'indices': [1397, 6951, 5114, 7624], 'tv loss': 5.8125, 'cleaning loss': 0.96875, 'ito loss': 3.640625, 'layer': 22}\n",
      "{'task': 'algo_second', 'weights': [104.80783081054688, 49.726593017578125, 46.8864631652832, 36.2938346862793, 31.6372013092041, 28.206867218017578, 15.582962989807129, 5.144576072692871], 'indices': [11265, 13143, 8898, 6950, 1029, 15471, 8060, 9587], 'tv loss': 5.78125, 'cleaning loss': 1.15625, 'ito loss': 5.28125, 'layer': 14}\n",
      "{'task': 'algo_second', 'weights': [68.54373168945312, 62.10304641723633, 60.16154098510742, 58.69261169433594, 36.09355163574219, 32.85321044921875, 30.50284194946289, 18.24876594543457, 17.699831008911133, 16.420833587646484], 'indices': [741, 3557, 4291, 1848, 1281, 7301, 809, 14919, 1130, 14622], 'tv loss': 4.9375, 'cleaning loss': 0.8359375, 'ito loss': 4.9375, 'layer': 16}\n",
      "{'task': 'algo_second', 'weights': [61.7536735534668, 53.964141845703125, 47.337703704833984, 44.89353942871094, 34.59163284301758, 19.043184280395508, 7.72219181060791], 'indices': [10619, 14772, 15759, 10953, 13880, 15992, 6589], 'tv loss': 5.09375, 'cleaning loss': 0.91015625, 'ito loss': 5.375, 'layer': 18}\n",
      "{'task': 'algo_second', 'weights': [83.0264663696289, 73.63509368896484, 57.32911682128906, 45.81797409057617, 38.497249603271484, 30.349933624267578, 15.686330795288086, 15.610630989074707, 12.35694408416748], 'indices': [8703, 16147, 5328, 8647, 2928, 7445, 6814, 10388, 9356], 'tv loss': 6.6875, 'cleaning loss': 2.578125, 'ito loss': 5.15625, 'layer': 20}\n",
      "{'task': 'algo_second', 'weights': [87.37236785888672, 84.75436401367188, 80.57061004638672, 69.29170989990234], 'indices': [6951, 16336, 344, 13834], 'tv loss': 7.75, 'cleaning loss': 4.65625, 'ito loss': 5.4375, 'layer': 22}\n",
      "{'task': 'location_continent', 'weights': [81.92717742919922, 69.89232635498047, 51.056583404541016, 35.19112014770508, 21.60094451904297, 10.573086738586426, 6.847681522369385, 5.356685638427734], 'indices': [7416, 14731, 15471, 13434, 2411, 3526, 798, 15492], 'tv loss': 7.34375, 'cleaning loss': 4.65625, 'ito loss': 8.875, 'layer': 14}\n",
      "{'task': 'location_continent', 'weights': [70.40492248535156, 51.627681732177734, 44.867008209228516, 43.30427169799805, 42.89949417114258, 10.516780853271484], 'indices': [3100, 7173, 15139, 4706, 318, 12691], 'tv loss': 5.875, 'cleaning loss': 5.125, 'ito loss': 8.5625, 'layer': 16}\n",
      "{'task': 'location_continent', 'weights': [56.45586013793945, 50.60417556762695, 44.43773651123047, 38.548789978027344, 32.85064697265625, 11.079436302185059, 10.270929336547852], 'indices': [2888, 12509, 1218, 5870, 2735, 524, 1332], 'tv loss': 4.125, 'cleaning loss': 3.625, 'ito loss': 6.53125, 'layer': 18}\n",
      "{'task': 'location_continent', 'weights': [95.22531127929688, 92.73229217529297, 61.31199264526367, 57.76387405395508, 40.90480422973633, 25.602001190185547, 17.414913177490234], 'indices': [5927, 8093, 3122, 13244, 2092, 14610, 9345], 'tv loss': 2.828125, 'cleaning loss': 0.72265625, 'ito loss': 4.625, 'layer': 20}\n",
      "{'task': 'football_player_position', 'weights': [88.87531280517578, 77.5062484741211, 60.747222900390625, 51.555545806884766, 50.31571960449219, 34.62760925292969, 31.65922737121582], 'indices': [8340, 798, 4636, 15471, 14666, 10647, 11664], 'tv loss': 9.9375, 'cleaning loss': 2.703125, 'ito loss': 10.9375, 'layer': 14}\n",
      "{'task': 'football_player_position', 'weights': [72.08625030517578, 59.42117691040039, 55.03669357299805, 51.4145622253418, 50.847900390625, 49.77424621582031, 47.349708557128906, 26.01964569091797, 21.99553108215332], 'indices': [318, 1281, 15430, 13847, 11801, 488, 15401, 14919, 10709], 'tv loss': 6.65625, 'cleaning loss': 2.28125, 'ito loss': 9.0, 'layer': 16}\n",
      "{'task': 'football_player_position', 'weights': [57.28505325317383, 55.09831237792969, 38.39909362792969, 35.50244140625, 35.297672271728516, 29.52569580078125, 26.56341552734375, 10.570446968078613, 4.658840656280518], 'indices': [2097, 15135, 5927, 9127, 1222, 10640, 5870, 1798, 9918], 'tv loss': 4.78125, 'cleaning loss': 2.359375, 'ito loss': 6.09375, 'layer': 18}\n",
      "{'task': 'football_player_position', 'weights': [87.46794128417969, 71.57099151611328, 45.45193099975586, 34.659523010253906, 28.709056854248047, 24.756072998046875, 23.353532791137695, 20.375675201416016, 6.185883045196533], 'indices': [11572, 437, 12448, 4717, 4289, 15184, 3086, 3462, 16330], 'tv loss': 4.125, 'cleaning loss': 2.59375, 'ito loss': 5.5625, 'layer': 20}\n",
      "{'task': 'location_religion', 'weights': [81.29733276367188, 71.83430480957031, 64.00182342529297, 43.872066497802734, 35.1648063659668, 29.150833129882812, 20.167198181152344], 'indices': [10021, 13037, 10637, 6, 12345, 15471, 798], 'tv loss': 6.78125, 'cleaning loss': 3.671875, 'ito loss': 7.78125, 'layer': 14}\n",
      "{'task': 'location_religion', 'weights': [56.97654342651367, 49.58552932739258, 44.182960510253906, 31.932523727416992, 22.616973876953125, 13.607062339782715, 13.490880966186523, 6.006885528564453], 'indices': [14220, 15139, 3997, 9295, 15430, 11711, 2087, 4141], 'tv loss': 5.5625, 'cleaning loss': 3.578125, 'ito loss': 7.96875, 'layer': 16}\n",
      "{'task': 'location_religion', 'weights': [65.96684265136719, 39.0623779296875, 38.30843734741211, 36.674583435058594, 34.02398681640625, 20.486961364746094, 17.610313415527344, 8.893712043762207], 'indices': [12665, 5247, 14103, 6425, 10861, 13286, 6113, 12812], 'tv loss': 3.375, 'cleaning loss': 2.3125, 'ito loss': 4.9375, 'layer': 18}\n",
      "{'task': 'location_religion', 'weights': [76.63591766357422, 60.20621109008789, 49.030487060546875, 45.26893997192383, 25.74622344970703, 14.660605430603027], 'indices': [9017, 4309, 3607, 3462, 56, 1479], 'tv loss': 1.9296875, 'cleaning loss': 1.7109375, 'ito loss': 3.28125, 'layer': 20}\n",
      "{'task': 'location_language', 'weights': [71.48603057861328, 68.83428192138672, 66.99116516113281, 57.76102828979492, 57.7516975402832, 16.972700119018555, 7.613239765167236], 'indices': [13927, 798, 4780, 15471, 13459, 15603, 10637], 'tv loss': 5.28125, 'cleaning loss': 3.515625, 'ito loss': 6.4375, 'layer': 14}\n",
      "{'task': 'location_language', 'weights': [63.32508850097656, 26.578855514526367, 21.784788131713867, 16.59748649597168, 8.179590225219727, 7.956859588623047, 5.945434093475342], 'indices': [4177, 3922, 14959, 2521, 15139, 15191, 9281], 'tv loss': 3.953125, 'cleaning loss': 1.2265625, 'ito loss': 5.3125, 'layer': 16}\n",
      "{'task': 'location_language', 'weights': [57.72123336791992, 43.30167007446289, 23.11332893371582], 'indices': [14742, 10037, 14146], 'tv loss': 1.484375, 'cleaning loss': 1.2421875, 'ito loss': 1.640625, 'layer': 18}\n",
      "{'task': 'location_language', 'weights': [110.853271484375, 42.12778091430664], 'indices': [296, 13204], 'tv loss': 1.140625, 'cleaning loss': 1.1484375, 'ito loss': 1.21875, 'layer': 20}\n",
      "{'task': 'person_profession', 'weights': [89.08818054199219, 66.29630279541016, 55.262935638427734, 50.72465133666992, 47.73493957519531, 37.44404983520508, 30.45914077758789, 25.28825569152832, 21.389493942260742], 'indices': [15471, 798, 257, 14349, 10647, 11205, 1033, 10637, 5756], 'tv loss': 8.25, 'cleaning loss': 4.53125, 'ito loss': 9.0625, 'layer': 14}\n",
      "{'task': 'person_profession', 'weights': [73.92292022705078, 72.74060821533203, 62.992576599121094, 37.89915084838867, 28.267107009887695, 25.923473358154297, 24.479907989501953, 23.57801055908203, 15.622322082519531, 8.487311363220215, 5.209859371185303], 'indices': [318, 15430, 784, 1130, 6051, 14220, 7502, 10709, 488, 10027, 14919], 'tv loss': 5.1875, 'cleaning loss': 3.859375, 'ito loss': 9.4375, 'layer': 16}\n",
      "{'task': 'person_profession', 'weights': [65.15151977539062, 50.096675872802734, 48.944183349609375, 18.902021408081055, 17.285404205322266, 8.165136337280273], 'indices': [1222, 5457, 13337, 14134, 1541, 15142], 'tv loss': 4.21875, 'cleaning loss': 3.015625, 'ito loss': 5.9375, 'layer': 18}\n",
      "{'task': 'person_profession', 'weights': [90.80447387695312, 60.78446960449219, 57.11018753051758, 43.86733627319336, 32.99556350708008, 29.643142700195312, 29.09367561340332, 19.323957443237305, 10.226627349853516, 7.50791597366333], 'indices': [3086, 14813, 3462, 4505, 15192, 12215, 14923, 437, 13229, 6793], 'tv loss': 3.859375, 'cleaning loss': 3.359375, 'ito loss': 4.96875, 'layer': 20}\n",
      "{'task': 'location_country', 'weights': [49.58774948120117, 27.387659072875977, 17.83387565612793, 15.037790298461914], 'indices': [15649, 10637, 7620, 8536], 'tv loss': 3.75, 'cleaning loss': 3.671875, 'ito loss': 4.59375, 'layer': 14}\n",
      "{'task': 'location_country', 'weights': [42.06240463256836, 38.933509826660156, 28.979257583618164, 22.618999481201172, 18.00539207458496, 17.236461639404297, 14.429204940795898, 12.997425079345703, 6.75364351272583, 5.39101505279541], 'indices': [15139, 4706, 1281, 2087, 7645, 14198, 15191, 14919, 6094, 318], 'tv loss': 3.1875, 'cleaning loss': 2.984375, 'ito loss': 3.921875, 'layer': 16}\n",
      "{'task': 'location_country', 'weights': [45.969757080078125, 40.13121032714844, 28.472131729125977], 'indices': [12593, 1332, 14022], 'tv loss': 3.0, 'cleaning loss': 2.375, 'ito loss': 2.984375, 'layer': 18}\n",
      "{'task': 'location_country', 'weights': [52.15965270996094, 42.56245422363281, 36.65980529785156, 25.76639747619629, 21.635221481323242, 13.12454605102539], 'indices': [5927, 2092, 13882, 2593, 2889, 2121], 'tv loss': 3.171875, 'cleaning loss': 2.71875, 'ito loss': 2.65625, 'layer': 20}\n",
      "{'task': 'country_capital', 'weights': [61.386898040771484, 34.624481201171875, 30.010469436645508, 16.02014923095703], 'indices': [3526, 3885, 6950, 8536], 'tv loss': 4.1875, 'cleaning loss': 2.15625, 'ito loss': 5.125, 'layer': 14}\n",
      "{'task': 'country_capital', 'weights': [66.35401153564453, 10.497588157653809], 'indices': [1816, 15191], 'tv loss': 3.90625, 'cleaning loss': 1.53125, 'ito loss': 4.40625, 'layer': 16}\n",
      "{'task': 'country_capital', 'weights': [53.93820571899414, 36.78972625732422, 21.455692291259766], 'indices': [15766, 12593, 11803], 'tv loss': 2.640625, 'cleaning loss': 1.46875, 'ito loss': 1.953125, 'layer': 18}\n",
      "{'task': 'country_capital', 'weights': [90.02557373046875, 54.27472686767578, 48.070648193359375], 'indices': [13882, 2121, 5927], 'tv loss': 2.90625, 'cleaning loss': 2.109375, 'ito loss': 1.65625, 'layer': 20}\n",
      "{'task': 'person_language', 'weights': [67.73258209228516, 57.72935485839844, 51.04296112060547, 41.44385528564453, 40.43260955810547, 24.604463577270508, 22.401653289794922, 4.520528793334961], 'indices': [13037, 798, 11280, 11205, 257, 4780, 15471, 10637], 'tv loss': 5.96875, 'cleaning loss': 3.1875, 'ito loss': 6.90625, 'layer': 14}\n",
      "{'task': 'person_language', 'weights': [71.04208374023438, 54.37769317626953, 27.30169105529785, 3.3321404457092285], 'indices': [4177, 15139, 2521, 2673], 'tv loss': 4.03125, 'cleaning loss': 1.5859375, 'ito loss': 6.53125, 'layer': 16}\n",
      "{'task': 'person_language', 'weights': [59.17557144165039, 36.085323333740234, 15.863348007202148, 8.239021301269531, 4.324285507202148], 'indices': [14742, 10037, 15344, 1218, 13286], 'tv loss': 2.296875, 'cleaning loss': 1.4296875, 'ito loss': 3.1875, 'layer': 18}\n",
      "{'task': 'person_language', 'weights': [98.97691345214844, 37.22072982788086, 14.148303031921387], 'indices': [296, 13204, 6385], 'tv loss': 1.609375, 'cleaning loss': 1.46875, 'ito loss': 1.5625, 'layer': 20}\n",
      "{'task': 'singular_plural', 'weights': [100.0541000366211, 59.70522689819336, 41.95180130004883], 'indices': [10027, 10842, 769], 'tv loss': 4.875, 'cleaning loss': 3.515625, 'ito loss': 5.34375, 'layer': 14}\n",
      "{'task': 'singular_plural', 'weights': [64.01258850097656, 49.365169525146484, 36.3176383972168, 30.33403205871582, 28.028230667114258, 26.167221069335938, 16.605363845825195, 8.064407348632812], 'indices': [2861, 3404, 11495, 7763, 1281, 5637, 318, 14919], 'tv loss': 3.71875, 'cleaning loss': 2.671875, 'ito loss': 4.375, 'layer': 16}\n",
      "{'task': 'singular_plural', 'weights': [42.86273193359375, 40.48654556274414, 33.178314208984375, 29.851045608520508, 28.106775283813477, 27.138301849365234, 23.61834144592285], 'indices': [14456, 8796, 7761, 11362, 15577, 11687, 8428], 'tv loss': 3.25, 'cleaning loss': 2.703125, 'ito loss': 4.21875, 'layer': 18}\n",
      "{'task': 'singular_plural', 'weights': [69.70197296142578, 56.32366943359375, 40.32952880859375, 34.66190719604492, 33.49922180175781, 12.947001457214355], 'indices': [9944, 5081, 2977, 3370, 6433, 12492], 'tv loss': 3.78125, 'cleaning loss': 3.25, 'ito loss': 2.984375, 'layer': 20}\n",
      "{'task': 'present_simple_past_simple', 'weights': [82.7536849975586, 79.3410873413086, 76.45652770996094, 34.454830169677734, 23.491086959838867, 19.23061752319336], 'indices': [10027, 327, 9463, 4446, 7152, 10842], 'tv loss': 6.3125, 'cleaning loss': 1.8828125, 'ito loss': 6.625, 'layer': 14}\n",
      "{'task': 'present_simple_past_simple', 'weights': [88.21328735351562, 71.17105102539062, 66.45825958251953, 57.026123046875, 56.1627311706543, 54.85511779785156, 51.02800750732422, 43.431671142578125], 'indices': [1281, 2861, 7763, 9083, 9234, 318, 5096, 15737], 'tv loss': 3.78125, 'cleaning loss': 0.9453125, 'ito loss': 5.25, 'layer': 16}\n",
      "{'task': 'present_simple_past_simple', 'weights': [46.4755973815918, 35.97052764892578, 34.356571197509766, 32.38611602783203, 31.3145809173584, 31.28382110595703, 30.196653366088867, 29.9758243560791, 25.260902404785156, 19.41943359375, 17.89089012145996, 8.196927070617676], 'indices': [14142, 7761, 11030, 14456, 4009, 9645, 14617, 11679, 14248, 13870, 5718, 12865], 'tv loss': 1.28125, 'cleaning loss': 0.79296875, 'ito loss': 2.5, 'layer': 18}\n",
      "{'task': 'present_simple_past_simple', 'weights': [46.1973762512207, 36.775184631347656, 34.43059158325195, 33.86598205566406, 32.72660827636719, 29.081344604492188, 27.025218963623047, 26.16314697265625, 22.7937068939209, 21.977336883544922, 17.770233154296875, 17.09629249572754, 10.602883338928223, 5.590720176696777, 5.5663862228393555], 'indices': [12492, 8083, 5755, 12790, 15613, 14296, 9220, 1924, 3079, 4530, 6867, 3013, 2977, 5328, 9268], 'tv loss': 1.46875, 'cleaning loss': 1.234375, 'ito loss': 2.59375, 'layer': 20}\n",
      "{'task': 'antonyms', 'weights': [42.22575759887695, 33.31382751464844, 20.53183364868164, 10.723810195922852, 9.74434757232666], 'indices': [5088, 7476, 14554, 15471, 3858], 'tv loss': 3.328125, 'cleaning loss': 1.7734375, 'ito loss': 2.65625, 'layer': 14}\n",
      "{'task': 'antonyms', 'weights': [37.47328186035156, 29.747655868530273, 29.382854461669922, 29.309999465942383, 27.064929962158203, 23.06216812133789, 17.359264373779297, 16.889184951782227, 14.56368637084961, 5.486828327178955, 4.136031627655029], 'indices': [1281, 4291, 1847, 9586, 14842, 10373, 883, 318, 14919, 5604, 2606], 'tv loss': 1.96875, 'cleaning loss': 1.7578125, 'ito loss': 2.640625, 'layer': 16}\n",
      "{'task': 'antonyms', 'weights': [59.69463348388672, 39.20282745361328, 17.360885620117188, 10.99362564086914, 10.054527282714844, 8.430277824401855], 'indices': [422, 10640, 13286, 8695, 2502, 5681], 'tv loss': 2.84375, 'cleaning loss': 3.3125, 'ito loss': 3.359375, 'layer': 18}\n",
      "{'task': 'antonyms', 'weights': [68.3149642944336, 42.97119140625, 40.44959259033203, 37.48350524902344], 'indices': [14763, 13099, 12423, 7333], 'tv loss': 3.546875, 'cleaning loss': 3.671875, 'ito loss': 4.3125, 'layer': 20}\n",
      "{'task': 'plural_singular', 'weights': [95.0749740600586, 61.63319778442383], 'indices': [3456, 10027], 'tv loss': 2.421875, 'cleaning loss': 1.765625, 'ito loss': 2.75, 'layer': 14}\n",
      "{'task': 'plural_singular', 'weights': [79.8563003540039, 58.15184020996094], 'indices': [2861, 8730], 'tv loss': 1.4921875, 'cleaning loss': 2.03125, 'ito loss': 2.15625, 'layer': 16}\n",
      "{'task': 'plural_singular', 'weights': [61.10221481323242, 42.97056198120117, 34.952880859375], 'indices': [14178, 14103, 14456], 'tv loss': 1.984375, 'cleaning loss': 1.4140625, 'ito loss': 2.265625, 'layer': 18}\n",
      "{'task': 'plural_singular', 'weights': [76.53192901611328, 65.25399017333984, 54.117610931396484, 46.49676513671875], 'indices': [2977, 12492, 6433, 3462], 'tv loss': 2.546875, 'cleaning loss': 2.15625, 'ito loss': 1.6171875, 'layer': 20}\n",
      "{'task': 'present_simple_past_perfect', 'weights': [80.48521423339844, 75.52290344238281, 57.05550765991211, 8.783214569091797], 'indices': [327, 10027, 9463, 10842], 'tv loss': 7.1875, 'cleaning loss': 4.59375, 'ito loss': 7.53125, 'layer': 14}\n",
      "{'task': 'present_simple_past_perfect', 'weights': [72.27371215820312, 58.920005798339844, 43.17791748046875, 33.516700744628906, 33.215431213378906, 31.230239868164062, 15.537097930908203, 4.621864318847656], 'indices': [2861, 7763, 9083, 12878, 1281, 15737, 7796, 318], 'tv loss': 5.65625, 'cleaning loss': 3.90625, 'ito loss': 6.4375, 'layer': 16}\n",
      "{'task': 'present_simple_past_perfect', 'weights': [69.85372161865234, 68.77824401855469, 40.23527145385742, 22.0433406829834, 20.43077850341797], 'indices': [14142, 7761, 9645, 14617, 5718], 'tv loss': 3.375, 'cleaning loss': 3.328125, 'ito loss': 5.5625, 'layer': 18}\n",
      "{'task': 'present_simple_past_perfect', 'weights': [54.91389846801758, 41.24119186401367, 38.71683120727539, 24.784011840820312, 19.244348526000977, 15.007511138916016, 8.660440444946289], 'indices': [172, 15613, 1924, 12492, 5755, 3079, 2977], 'tv loss': 3.3125, 'cleaning loss': 3.59375, 'ito loss': 5.53125, 'layer': 20}\n",
      "{'task': 'present_simple_gerund', 'weights': [103.68135070800781, 95.31483459472656, 52.54801559448242, 51.08197784423828, 6.341806411743164], 'indices': [9463, 10027, 4446, 167, 761], 'tv loss': 7.34375, 'cleaning loss': 1.4140625, 'ito loss': 7.21875, 'layer': 14}\n",
      "{'task': 'present_simple_gerund', 'weights': [34.703102111816406, 34.06485366821289, 32.88654708862305, 26.984405517578125, 26.158485412597656, 22.74032211303711, 20.326133728027344, 16.20465087890625], 'indices': [1281, 2861, 4592, 5637, 5096, 3683, 7583, 318], 'tv loss': 4.40625, 'cleaning loss': 1.9296875, 'ito loss': 5.375, 'layer': 16}\n",
      "{'task': 'present_simple_gerund', 'weights': [52.60050964355469, 44.801273345947266, 38.557857513427734, 29.51311683654785, 25.617401123046875, 14.265189170837402, 13.988640785217285], 'indices': [10437, 14178, 15305, 14248, 14456, 4009, 4225], 'tv loss': 1.5546875, 'cleaning loss': 1.78125, 'ito loss': 1.53125, 'layer': 18}\n",
      "{'task': 'present_simple_gerund', 'weights': [75.66523742675781, 72.48921966552734, 70.72652435302734, 59.42861557006836, 29.668758392333984, 21.590917587280273], 'indices': [12790, 7564, 2977, 11864, 12492, 663], 'tv loss': 2.125, 'cleaning loss': 1.90625, 'ito loss': 1.703125, 'layer': 20}\n",
      "{'task': 'en_it', 'weights': [35.650691986083984, 35.36211013793945, 32.943321228027344, 30.651350021362305, 29.178743362426758, 20.260356903076172, 9.653030395507812, 9.11665153503418, 4.646912574768066], 'indices': [6791, 10842, 9463, 12371, 11259, 7620, 15471, 10021, 7152], 'tv loss': 13.6875, 'cleaning loss': 5.84375, 'ito loss': 15.625, 'layer': 14}\n",
      "{'task': 'en_it', 'weights': [57.950042724609375, 43.8196907043457, 42.875850677490234, 35.340538024902344, 30.427356719970703, 26.534032821655273, 14.319297790527344, 14.096945762634277, 11.004179000854492, 6.237576961517334, 4.418542861938477, 3.931884765625], 'indices': [16176, 1186, 318, 1174, 8333, 5637, 5817, 5640, 9083, 1281, 14919, 2087], 'tv loss': 6.5, 'cleaning loss': 1.8125, 'ito loss': 11.4375, 'layer': 16}\n",
      "{'task': 'en_it', 'weights': [91.76130676269531, 80.31692504882812, 53.408416748046875, 38.55136489868164, 36.84712600708008, 29.586048126220703, 25.1787166595459, 24.3840389251709, 21.48419952392578, 15.481626510620117, 12.416374206542969], 'indices': [12865, 4373, 10270, 5112, 7639, 14142, 15114, 7472, 890, 394, 14086], 'tv loss': 7.8125, 'cleaning loss': 3.171875, 'ito loss': 9.3125, 'layer': 18}\n",
      "{'task': 'en_it', 'weights': [115.81272888183594, 114.77272033691406, 69.2420654296875, 39.126678466796875, 32.97346496582031, 31.221773147583008, 24.07685089111328], 'indices': [8684, 16270, 7666, 16060, 14923, 12448, 6433], 'tv loss': 9.0625, 'cleaning loss': 4.625, 'ito loss': 10.625, 'layer': 20}\n",
      "{'task': 'it_en', 'weights': [48.17822265625, 35.601478576660156, 24.64922332763672, 21.422060012817383, 11.375746726989746], 'indices': [6791, 5803, 2449, 12735, 7520], 'tv loss': 5.03125, 'cleaning loss': 3.75, 'ito loss': 5.59375, 'layer': 14}\n",
      "{'task': 'it_en', 'weights': [57.49078369140625, 33.177738189697266, 23.69135093688965, 17.823945999145508, 10.956573486328125, 6.953406810760498, 6.762234687805176], 'indices': [10788, 1174, 11302, 1281, 502, 318, 14919], 'tv loss': 4.5625, 'cleaning loss': 3.890625, 'ito loss': 5.4375, 'layer': 16}\n",
      "{'task': 'it_en', 'weights': [76.65216064453125, 41.83615493774414, 38.673526763916016, 21.46650505065918, 10.105071067810059], 'indices': [2678, 10340, 14456, 10477, 3894], 'tv loss': 5.1875, 'cleaning loss': 4.21875, 'ito loss': 4.5, 'layer': 18}\n",
      "{'task': 'it_en', 'weights': [75.32768249511719, 66.33564758300781, 56.33060836791992, 25.38197135925293, 21.724716186523438], 'indices': [12231, 13229, 6814, 12492, 12790], 'tv loss': 5.0, 'cleaning loss': 4.59375, 'ito loss': 4.78125, 'layer': 20}\n",
      "{'task': 'en_fr', 'weights': [55.87138748168945, 36.81239318847656, 33.636810302734375, 30.2867488861084, 27.505237579345703, 18.150920867919922, 14.444929122924805, 5.2421159744262695], 'indices': [9463, 12371, 10842, 7152, 11259, 10027, 7620, 15471], 'tv loss': 14.25, 'cleaning loss': 6.0625, 'ito loss': 15.9375, 'layer': 14}\n",
      "{'task': 'en_fr', 'weights': [54.97054672241211, 45.620811462402344, 45.167808532714844, 45.09112548828125, 27.306678771972656, 25.831518173217773, 24.913557052612305, 24.879358291625977, 20.63060760498047, 8.299830436706543], 'indices': [318, 1174, 16176, 8703, 8333, 2087, 14919, 1281, 5817, 7645], 'tv loss': 8.0625, 'cleaning loss': 2.59375, 'ito loss': 11.5625, 'layer': 16}\n",
      "{'task': 'en_fr', 'weights': [66.47498321533203, 63.284271240234375, 40.440250396728516, 36.525386810302734, 36.234859466552734, 33.76182174682617, 27.351594924926758, 22.43858528137207, 21.961952209472656, 19.09722328186035, 13.394230842590332, 12.214226722717285], 'indices': [4373, 12865, 4571, 7639, 14142, 5112, 10225, 15344, 15114, 394, 1154, 14086], 'tv loss': 8.25, 'cleaning loss': 3.265625, 'ito loss': 12.5625, 'layer': 18}\n",
      "{'task': 'en_fr', 'weights': [97.11351776123047, 67.59243774414062, 65.53396606445312, 45.31163024902344, 39.84504699707031, 36.059444427490234], 'indices': [694, 8684, 13952, 12384, 14923, 16060], 'tv loss': 9.3125, 'cleaning loss': 4.84375, 'ito loss': 10.625, 'layer': 20}\n",
      "{'task': 'en_es', 'weights': [78.07878112792969, 64.23641204833984, 61.6251220703125, 47.04054641723633, 43.258453369140625, 34.35911560058594, 21.712459564208984, 12.748682022094727, 9.400870323181152], 'indices': [12371, 9463, 12780, 7152, 3456, 7620, 7520, 761, 4493], 'tv loss': 14.125, 'cleaning loss': 3.984375, 'ito loss': 15.625, 'layer': 14}\n",
      "{'task': 'en_es', 'weights': [50.53876876831055, 40.5326042175293, 34.384437561035156, 29.049203872680664, 23.3153133392334, 22.735107421875, 21.643299102783203, 21.240327835083008, 19.398113250732422, 16.596389770507812, 13.091792106628418, 9.562026023864746], 'indices': [318, 16176, 5640, 1281, 5637, 14919, 15683, 8333, 1174, 5661, 5817, 9083], 'tv loss': 6.1875, 'cleaning loss': 1.3046875, 'ito loss': 8.375, 'layer': 16}\n",
      "{'task': 'en_es', 'weights': [58.195098876953125, 44.15866470336914, 41.50706481933594, 33.94339370727539, 30.198787689208984, 27.760805130004883, 24.619428634643555, 19.329513549804688, 13.993512153625488], 'indices': [12865, 4373, 5112, 7639, 12802, 5049, 3880, 15114, 14086], 'tv loss': 6.625, 'cleaning loss': 2.28125, 'ito loss': 12.5625, 'layer': 18}\n",
      "{'task': 'en_es', 'weights': [119.75859832763672, 99.33477020263672, 69.00123596191406, 45.18467712402344, 10.218131065368652], 'indices': [8684, 12402, 14923, 16060, 644], 'tv loss': 8.75, 'cleaning loss': 3.359375, 'ito loss': 11.1875, 'layer': 20}\n",
      "{'task': 'fr_en', 'weights': [44.803993225097656, 38.963653564453125, 24.393232345581055, 23.838613510131836, 6.455591678619385], 'indices': [5803, 12735, 15471, 2449, 5659], 'tv loss': 2.8125, 'cleaning loss': 1.765625, 'ito loss': 3.5, 'layer': 14}\n",
      "{'task': 'fr_en', 'weights': [50.724300384521484, 29.719959259033203, 10.045334815979004, 4.045902729034424], 'indices': [10788, 11302, 1281, 502], 'tv loss': 2.125, 'cleaning loss': 1.8984375, 'ito loss': 2.90625, 'layer': 16}\n",
      "{'task': 'fr_en', 'weights': [42.788658142089844, 24.483190536499023, 22.231874465942383, 17.99167823791504, 7.815559387207031, 7.057303428649902, 5.621116638183594, 5.022383213043213], 'indices': [10340, 2678, 14456, 12865, 10477, 6606, 2502, 11871], 'tv loss': 3.375, 'cleaning loss': 2.46875, 'ito loss': 2.15625, 'layer': 18}\n",
      "{'task': 'fr_en', 'weights': [60.64692306518555, 58.3690071105957, 21.782733917236328, 19.134296417236328, 14.104825019836426, 11.229310035705566], 'indices': [12231, 6814, 9268, 12492, 5328, 3013], 'tv loss': 3.53125, 'cleaning loss': 2.984375, 'ito loss': 2.546875, 'layer': 20}\n",
      "{'task': 'es_en', 'weights': [56.18315124511719, 31.331207275390625, 22.51227569580078, 4.760361671447754], 'indices': [6791, 5803, 12735, 7520], 'tv loss': 2.71875, 'cleaning loss': 1.84375, 'ito loss': 4.53125, 'layer': 14}\n",
      "{'task': 'es_en', 'weights': [61.12657165527344, 36.74671173095703, 22.547433853149414, 17.387859344482422, 8.07979679107666], 'indices': [10788, 1174, 11599, 11302, 1281], 'tv loss': 1.7265625, 'cleaning loss': 1.765625, 'ito loss': 2.828125, 'layer': 16}\n",
      "{'task': 'es_en', 'weights': [65.1798324584961, 37.63230895996094, 34.145450592041016, 33.41923522949219, 23.14604377746582], 'indices': [2678, 14456, 10340, 10477, 12865], 'tv loss': 3.078125, 'cleaning loss': 2.03125, 'ito loss': 2.03125, 'layer': 18}\n",
      "{'task': 'es_en', 'weights': [74.60662078857422, 69.68817138671875, 66.01045989990234, 46.952396392822266, 15.114033699035645], 'indices': [12231, 6814, 13229, 12492, 5328], 'tv loss': 2.6875, 'cleaning loss': 2.109375, 'ito loss': 2.359375, 'layer': 20}\n"
     ]
    }
   ],
   "source": [
    "with open(\"gemma_2_cleaning_compact.jsonl\", \"w\") as f:\n",
    "    for r in task_results:\n",
    "        task = r[\"task\"]\n",
    "        layer = r[\"layer\"]\n",
    "        \n",
    "        weights = np.array(r[\"weights\"])\n",
    "\n",
    "        i = np.argwhere(weights > thresholds[layer]).flatten()\n",
    "        w = weights[i]\n",
    "\n",
    "        idx = np.argsort(w)[::-1]\n",
    "\n",
    "        i = i[idx]\n",
    "        w = w[idx]\n",
    "\n",
    "        data = {\n",
    "            \"task\": task,\n",
    "            \"weights\": w.tolist(),\n",
    "            \"indices\": i.tolist(),\n",
    "            \"tv loss\": r[\"tv_loss\"],\n",
    "            \"cleaning loss\": r[\"loss\"],\n",
    "            \"ito loss\": r[\"ito_loss\"],\n",
    "            \"layer\": layer\n",
    "        }\n",
    "\n",
    "        print(data)\n",
    "        f.write(json.dumps(data) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micrlhf-progress-_SD4q1c9-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
