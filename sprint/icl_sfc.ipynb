{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if \"models\" not in os.listdir(\".\"):\n",
    "    os.chdir(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import penzai\n",
    "import jax_smi\n",
    "jax_smi.initialise_tracking()\n",
    "from penzai import pz\n",
    "pz.ts.register_as_default()\n",
    "pz.ts.register_autovisualize_magic()\n",
    "pz.enable_interactive_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from micrlhf.llama import LlamaTransformer\n",
    "llama = LlamaTransformer.from_pretrained(\"models/gemma-2b-it.gguf\", from_type=\"gemma\", load_eager=True, device_map=\"tpu:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"alpindale/gemma-2b\")\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sprint.task_vector_utils import load_tasks, ICLRunner\n",
    "tasks = load_tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763\n",
      "346\n"
     ]
    }
   ],
   "source": [
    "def check_if_single_token(token):\n",
    "    return len(tokenizer.tokenize(token)) == 1\n",
    "\n",
    "task_name = \"es_en\"\n",
    "\n",
    "task = tasks[task_name]\n",
    "\n",
    "print(len(task))\n",
    "\n",
    "task = {\n",
    "    k:v for k,v in task.items() if check_if_single_token(k) and check_if_single_token(v)\n",
    "}\n",
    "\n",
    "print(len(task))\n",
    "\n",
    "pairs = list(task.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logprob_loss(logits, tokens, sep=1599, pad_token=32000, n_first=None, shift=None):\n",
    "    logits = logits[:, :-1]\n",
    "\n",
    "    # print(\n",
    "    #     logits.argmax(axis=-1)\n",
    "    # )\n",
    "\n",
    "    logits = jnp.take_along_axis(logits, tokens[:, 1:, None], axis=-1).squeeze(-1)\n",
    "\n",
    "    mask = tokens[:, 1:] == sep\n",
    "    mask = jnp.cumsum(mask[:, ::-1], axis=-1)[:, ::-1] > 0\n",
    "    mask = jnp.logical_not(mask)\n",
    "\n",
    "    if shift is not None:\n",
    "        rolled_mask = jnp.roll(mask, shift, axis=-1)\n",
    "        mask = jnp.logical_and(mask, rolled_mask)\n",
    "\n",
    "    # print(mask[:, -5:])\n",
    "    \n",
    "    if n_first is not None:\n",
    "        rolled_mask = jnp.roll(mask, n_first, axis=-1)\n",
    "        mask = jnp.logical_and(mask, jnp.logical_not(rolled_mask))\n",
    "\n",
    "    mask = jnp.logical_and(mask, tokens[:, 1:] != pad_token)\n",
    "\n",
    "    logits = logits * mask\n",
    "\n",
    "    return logits.sum(axis=-1).mean(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "sep = 3978\n",
    "pad = 0\n",
    "\n",
    "def metric_fn(logits, resids, tokens):\n",
    "    return logprob_loss(logits, tokens, sep=sep, pad_token=pad, n_first=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from micrlhf.llama import LlamaBlock, LlamaAttention\n",
    "from micrlhf.utils.activation_manipulation import ActivationAddition, wrap_vector\n",
    "from functools import partial\n",
    "import jax.numpy as jnp\n",
    "from penzai import pz\n",
    "import jax\n",
    "\n",
    "@partial(jax.jit, static_argnames=(\"metric\", \"batched\"))\n",
    "def run_with_add(additions_pre, additions_mid, tokens, metric, batched=False, llama=None):\n",
    "    get_resids = llama.select().at_instances_of(LlamaBlock).apply_with_selected_index(lambda i, x:\n",
    "        pz.nn.Sequential([\n",
    "            pz.de.TellIntermediate.from_config(tag=f\"resid_pre_{i}\"),\n",
    "            x\n",
    "        ])\n",
    "    )\n",
    "    get_resids = get_resids.select().at_instances_of(LlamaBlock).apply_with_selected_index(lambda l, b: b.select().at_instances_of(pz.nn.Residual).apply_with_selected_index(lambda i, x: x if i == 0 else pz.nn.Sequential([\n",
    "        pz.de.TellIntermediate.from_config(tag=f\"resid_mid_{l}\"),\n",
    "        x,\n",
    "    ])))\n",
    "\n",
    "\n",
    "    get_resids = get_resids.select().at_instances_of(LlamaAttention).apply_with_selected_index(lambda i, x: x.select().at_instances_of(pz.nn.Softmax).apply(lambda b: pz.nn.Sequential([\n",
    "        b,\n",
    "        pz.de.TellIntermediate.from_config(tag=f\"attn_{i}\"),\n",
    "    ])))\n",
    "\n",
    "    get_resids = pz.de.CollectingSideOutputs.handling(get_resids, tag_predicate=lambda x: True)\n",
    "    make_additions = get_resids.select().at_instances_of(LlamaBlock).apply_with_selected_index(lambda i, x:\n",
    "        pz.nn.Sequential([\n",
    "            ActivationAddition(pz.nx.wrap(additions_pre[i], *((\"batch\",) if batched else ()), \"seq\", \"embedding\"), \"all\"),\n",
    "            x\n",
    "        ])\n",
    "    )\n",
    "    make_additions = make_additions.select().at_instances_of(LlamaBlock).apply_with_selected_index(lambda l, b: b.select().at_instances_of(pz.nn.Residual).apply_with_selected_index(lambda i, x: x if i == 0 else pz.nn.Sequential([\n",
    "        ActivationAddition(pz.nx.wrap(additions_mid[l], *((\"batch\",) if batched else ()), \"seq\", \"embedding\"), \"all\"),\n",
    "        x,\n",
    "    ])))\n",
    "    tokens_wrapped = pz.nx.wrap(tokens, \"batch\", \"seq\")\n",
    "    logits, resids = make_additions(llama.inputs.from_basic_segments(tokens_wrapped))\n",
    "    return metric(logits.unwrap(\"batch\", \"seq\", \"vocabulary\"), resids, tokens), (logits, resids[::3], resids[1::3], resids[2::3])\n",
    "\n",
    "\n",
    "@partial(jax.jit, static_argnames=(\"metric\",))\n",
    "def get_metric_resid_grad(tokens, llama=llama, metric=metric_fn):\n",
    "    additions = [jnp.zeros(tokens.shape + (llama.config.hidden_size,)) for _ in range(llama.config.num_layers)]\n",
    "    batched = tokens.ndim > 1\n",
    "    (metric, (logits, resids_pre, qk, resids_mid)), (grad_pre, grad_mid) = jax.value_and_grad(run_with_add, argnums=(0, 1), has_aux=True)(additions, additions, tokens, metric, batched=batched, llama=llama)\n",
    "    return (\n",
    "        metric,\n",
    "        [r.value.unwrap(\"batch\", \"seq\", \"embedding\") for r in resids_pre],\n",
    "        [r.value.unwrap(\"batch\", \"seq\", \"embedding\") for r in resids_mid],\n",
    "        [r.value.unwrap(\"batch\", \"kv_heads\", \"q_rep\", \"seq\", \"kv_seq\") for r in qk],\n",
    "        grad_pre,\n",
    "        grad_mid\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8 \n",
    "n_shot=20\n",
    "max_seq_len = 128\n",
    "seed = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Follow the pattern:\\n{}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = ICLRunner(task_name, pairs, batch_size=batch_size, n_shot=n_shot, max_seq_len=max_seq_len, seed=seed, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sprint.task_vector_utils import tokenized_to_inputs\n",
    "\n",
    "train_tokens = runner.get_tokens(\n",
    "    runner.train_pairs, tokenizer\n",
    ")[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_value, resids_pre, resids_mid, qk, grad_pre, grad_mid = get_metric_resid_grad(train_tokens, llama=llama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rms_block = lambda layer, resid_index: (\n",
    "    llama.select()\n",
    "    .at_instances_of(LlamaBlock).pick_nth_selected(layer)\n",
    "    .at_instances_of(pz.nn.Residual).pick_nth_selected(resid_index)\n",
    "    .at_instances_of(pz.nn.RMSLayerNorm).pick_nth_selected(0)\n",
    "    ).get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_rms = [get_rms_block(layer, 1) for layer in range(llama.config.num_layers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from micrlhf.utils.load_sae import get_nev_it_sae_suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from micrlhf.utils.load_sae import weights_to_resid, resids_to_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from micrlhf.utils.load_sae import sae_encode_gated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_normalize(layer, resid_mid):\n",
    "    # return resid_mid / resids_mid_norms[layer] * mlp_rms_weights[layer]\n",
    "    # return resid_mid / jnp.linalg.norm(resid_mid, axis=-1, keepdims=True) * mlp_rms_weights[layer]\n",
    "    return mlp_rms[layer](pz.nx.wrap(resid_mid, \"batch\", \"seq\", \"embedding\")).unwrap(\"batch\", \"seq\", \"embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b640ac75e8c8451ebd2e033d38eb1666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e111c3a6ca644ce9063d60036d822fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6d1a8ed5afe4cb4939f7e21e75619db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "ie_attn = {}\n",
    "sae_grads_attn = {}\n",
    "ie_resid = {}\n",
    "sae_grads_resid = {}\n",
    "ie_transcoder = {}\n",
    "sae_grads_transcoder = {}\n",
    "\n",
    "ie_error_attn = {}\n",
    "ie_error_resid = {}\n",
    "ie_error_transcoder = {}\n",
    "\n",
    "sae_error_attn = {}\n",
    "sae_error_resid = {}\n",
    "sae_error_transcoder = {}\n",
    "\n",
    "def sfc_simple(grad, resid, target, sae):\n",
    "    pre_relu, post_relu, recon = sae_encode_gated(sae, resid)\n",
    "    error = target - recon\n",
    "    f = partial(weights_to_resid, sae=sae)\n",
    "\n",
    "    sae_grad, = jax.vjp(f, post_relu)[1](grad,)\n",
    "    indirect_effects = sae_grad * post_relu\n",
    "    indirect_effects_error = jnp.einsum(\"...f, ...f -> ...\", grad, error)\n",
    "    return indirect_effects, indirect_effects_error, sae_grad, error\n",
    "\n",
    "\n",
    "layers = list(range(6, 17))\n",
    "for layer in tqdm(layers):\n",
    "    r_pre, r_mid, g_mid = resids_pre[layer], resids_mid[layer], grad_mid[layer]\n",
    "    sae = get_nev_it_sae_suite(layer=layer, label=\"attn_out\")\n",
    "    indirect_effects, indirect_effects_error, sae_grad, error = sfc_simple(g_mid, r_mid - r_pre, r_mid - r_pre, sae)\n",
    "    # display((indirect_effects > 0).sum(-1))\n",
    "    ie_attn[layer] = indirect_effects\n",
    "    ie_error_attn[layer] = indirect_effects_error\n",
    "    sae_grads_attn[layer] = sae_grad\n",
    "    sae_error_attn[layer] = error\n",
    "\n",
    "# for layer, (r_pre, g_pre) in enumerate(zip(resids_pre, grad_pre)):\n",
    "for layer in tqdm(layers):\n",
    "    r_pre, g_pre = resids_pre[layer], grad_pre[layer]\n",
    "    sae = get_nev_it_sae_suite(layer=layer)\n",
    "    indirect_effects, indirect_effects_error, sae_grad, error = sfc_simple(g_pre, r_pre, r_pre, sae)\n",
    "    # display((indirect_effects != 0).sum(-1))\n",
    "    ie_resid[layer] = indirect_effects\n",
    "    ie_error_resid[layer] = indirect_effects_error\n",
    "    sae_grads_resid[layer] = sae_grad\n",
    "    sae_error_resid[layer] = error\n",
    "\n",
    "for layer in tqdm(layers[:-1]):\n",
    "    r_mid, r_pre, g_pre = resids_mid[layer], resids_pre[layer + 1], grad_pre[layer + 1]\n",
    "    sae = get_nev_it_sae_suite(layer=layer, label=\"transcoder\")\n",
    "    indirect_effects, indirect_effects_error, sae_grad, error = sfc_simple(g_pre, mlp_normalize(layer, r_mid), r_pre - r_mid, sae)\n",
    "    # display((indirect_effects != 0).sum(-1))\n",
    "    ie_transcoder[layer] = indirect_effects\n",
    "    ie_error_transcoder[layer] = indirect_effects_error\n",
    "    sae_grads_transcoder[layer] = sae_grad\n",
    "    sae_error_transcoder[layer] = error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_wrapped = pz.nx.wrap(train_tokens, \"batch\", \"seq\")\n",
    "llama_inputs = llama.inputs.from_basic_segments(tokens_wrapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def attn_call(layer, resid_pre):\n",
    "#     subblock = llama.select().at_instances_of(LlamaBlock).pick_nth_selected(layer).at_instances_of(pz.nn.Residual).pick_nth_selected(0).get().delta\n",
    "#     subblock = subblock.select().at_instances_of(LlamaAttention).get()\n",
    "\n",
    "#     si_selection = subblock.select().at_instances_of(pz.de.HandledSideInputRef)\n",
    "#     keys = sorted(set([ref.tag for ref in si_selection.get_sequence()]))\n",
    "#     replaced = si_selection.apply(lambda ref: pz.de.SideInputRequest(tag=ref.tag))\n",
    "#     subblock = pz.de.WithSideInputsFromInputTuple.handling(replaced, keys)\n",
    "\n",
    "#     side_inputs = {\n",
    "#         'positions': llama_inputs.positions,\n",
    "#         'attn_mask': llama_inputs.attention_mask\n",
    "#     }\n",
    "    \n",
    "#     resid_pre = resid_pre / \n",
    "\n",
    "#     resid_pre = pz.nx.wrap(resid_pre, \"batch\", \"seq\", \"embedding\")\n",
    "#     attn_out = subblock((resid_pre,) + tuple(side_inputs[tag] for tag in subblock.side_input_tags))\n",
    "\n",
    "#     attn_out = attn_out.unwrap(\"batch\", \"seq\", \"embedding\") \n",
    "\n",
    "#     return attn_out.astype(resid.dtype)\n",
    "\n",
    "# attn_call(6, resids_pre[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_length = len(tokenizer.tokenize(prompt))\n",
    "periods = [\"input\", \"arrow\", \"output\", \"newline\"]\n",
    "masks = {\n",
    "    \"prompt\": jnp.zeros_like(train_tokens).at[:, :prompt_length].set(1).astype(bool),\n",
    "    **{\n",
    "        period: jnp.zeros_like(train_tokens).at[:, prompt_length+i::len(periods)].set(1).astype(bool) * (train_tokens != pad) for i, period in enumerate(periods)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_average(vector, mask):\n",
    "    mask = masks[mask]\n",
    "    while mask.ndim < vector.ndim:\n",
    "        mask = mask[..., None]\n",
    "\n",
    "    return ((mask * vector).sum(1) / mask.sum(1)).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcoder_feature_to_mid(layer, feature_idx, mask):\n",
    "    sae = get_nev_it_sae_suite(layer=layer, label=\"transcoder\")\n",
    "    resid = resids_mid[layer]\n",
    "\n",
    "    def f(resid):\n",
    "        resid = mlp_normalize(layer, resid)\n",
    "        batch_token_feat = resids_to_weights(resid, sae)[:, :, feature_idx] * sae_grads_transcoder[layer][:, :, feature_idx]\n",
    "        token_act = mask_average(batch_token_feat, mask)\n",
    "        return token_act\n",
    "\n",
    "    return jax.grad(f)(resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcoder_error_to_mid(layer, mask):\n",
    "    sae = get_nev_it_sae_suite(layer=layer, label=\"transcoder\")\n",
    "    resid_next = resids_pre[layer + 1]\n",
    "    resid = resids_mid[layer]\n",
    "\n",
    "    grad = grad_pre[layer + 1]\n",
    "\n",
    "    def f(resid):\n",
    "        _, _, recon = sae_encode_gated(sae, resid)\n",
    "        err_by_grad = jnp.einsum(\"...f, ...f -> ...\", (resid_next - recon), grad)\n",
    "        return mask_average(err_by_grad, mask)\n",
    "\n",
    "    return jax.grad(f)(resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attn_out_feature_to_pre(layer, feature_idx, mask):\n",
    "    sae = get_nev_it_sae_suite(layer=layer, label=\"attn_out\")\n",
    "\n",
    "    resid = resids_pre[layer]\n",
    "\n",
    "    subblock = llama.select().at_instances_of(LlamaBlock).pick_nth_selected(layer).at_instances_of(pz.nn.Residual).pick_nth_selected(0).get().delta\n",
    "\n",
    "    si_selection = subblock.select().at_instances_of(pz.de.HandledSideInputRef)\n",
    "    keys = sorted(set([ref.tag for ref in si_selection.get_sequence()]))\n",
    "    replaced = si_selection.apply(lambda ref: pz.de.SideInputRequest(tag=ref.tag))\n",
    "    subblock = pz.de.WithSideInputsFromInputTuple.handling(replaced, keys)\n",
    "\n",
    "    side_inputs = {\n",
    "        'positions': llama_inputs.positions,\n",
    "        'attn_mask': llama_inputs.attention_mask\n",
    "    }\n",
    "\n",
    "    def f(resid):\n",
    "        resid = pz.nx.wrap(resid, \"batch\", \"seq\", \"embedding\")\n",
    "        attn_out = subblock((resid,) + tuple(side_inputs[tag] for tag in subblock.side_input_tags))\n",
    "\n",
    "        attn_out = attn_out.unwrap(\"batch\", \"seq\", \"embedding\") \n",
    "\n",
    "        batch_token_feat = resids_to_weights(attn_out, sae)[:, :, feature_idx] * sae_grads_attn[layer][:, :, feature_idx]\n",
    "        token_act = mask_average(batch_token_feat, mask)\n",
    "        return token_act\n",
    "\n",
    "    return jax.grad(f)(resid)\n",
    "\n",
    "def attn_out_error_to_pre(layer, mask):\n",
    "    sae = get_nev_it_sae_suite(layer=layer, label=\"attn_out\")\n",
    "\n",
    "    resid = resids_pre[layer]\n",
    "\n",
    "    subblock = llama.select().at_instances_of(LlamaBlock).pick_nth_selected(layer).at_instances_of(pz.nn.Residual).pick_nth_selected(0).get().delta\n",
    "\n",
    "    si_selection = subblock.select().at_instances_of(pz.de.HandledSideInputRef)\n",
    "    keys = sorted(set([ref.tag for ref in si_selection.get_sequence()]))\n",
    "    replaced = si_selection.apply(lambda ref: pz.de.SideInputRequest(tag=ref.tag))\n",
    "    subblock = pz.de.WithSideInputsFromInputTuple.handling(replaced, keys)\n",
    "\n",
    "    side_inputs = {\n",
    "        'positions': llama_inputs.positions,\n",
    "        'attn_mask': llama_inputs.attention_mask\n",
    "    }\n",
    "\n",
    "    def f(resid):\n",
    "        resid = pz.nx.wrap(resid, \"batch\", \"seq\", \"embedding\")\n",
    "        attn_out = subblock((resid,) + tuple(side_inputs[tag] for tag in subblock.side_input_tags))\n",
    "\n",
    "        attn_out = attn_out.unwrap(\"batch\", \"seq\", \"embedding\") \n",
    "\n",
    "        _, _, recon = sae_encode_gated(sae, attn_out)\n",
    "        batch_token_feat = jnp.einsum(\"...f, ...f -> ...\", attn_out - recon, grad_mid[layer])\n",
    "        token_act = mask_average(batch_token_feat, mask)\n",
    "        return token_act\n",
    "\n",
    "    return jax.grad(f)(resid)\n",
    "# float(jnp.linalg.norm(attn_out_error_to_pre(6, \"arrow\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_feature_to_pre(layer, feature_idx, mask):\n",
    "    sae = get_nev_it_sae_suite(layer=layer)\n",
    "    resid = resids_pre[layer]\n",
    "\n",
    "    def f(resid):\n",
    "        batch_token_feat = resids_to_weights(resid, sae)[:, :, feature_idx] * sae_grads_resid[layer][:, :, feature_idx]\n",
    "        token_act = mask_average(batch_token_feat, mask)\n",
    "        return token_act\n",
    "\n",
    "    return jax.grad(f)(resid)\n",
    "\n",
    "def pre_error_to_pre(layer, mask):\n",
    "    sae = get_nev_it_sae_suite(layer=layer)\n",
    "    resid = resids_pre[layer]\n",
    "\n",
    "    def f(resid):\n",
    "        _, _, recon = sae_encode_gated(sae, resid)\n",
    "        batch_token_error = jnp.einsum(\"...f, ...f -> ...\", (resid - recon), grad_pre[layer])\n",
    "        token_grad = mask_average(batch_token_error, mask)\n",
    "        return token_grad\n",
    "\n",
    "    return jax.grad(f)(resid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ie_pre_to_transcoder_features(layer, grad, mask):\n",
    "    sae = get_nev_it_sae_suite(layer=layer, label=\"transcoder\")\n",
    "    resid_mid = resids_mid[layer]\n",
    "    resid_mid = mlp_normalize(layer, resid_mid)\n",
    "    ie = sfc_simple(grad, resid_mid, resid_mid, sae)[0]\n",
    "    ie = mask_average(ie, mask)\n",
    "\n",
    "    return ie\n",
    "\n",
    "def ie_pre_to_transcoder_error(layer, grad, mask):\n",
    "    sae = get_nev_it_sae_suite(layer=layer, label=\"transcoder\")\n",
    "    resid_next = resids_pre[layer + 1]\n",
    "    resid_mid = resids_mid[layer]\n",
    "    ie = sfc_simple(grad, mlp_normalize(layer, resid_mid), resid_next - resid_mid, sae)[1]\n",
    "    ie = mask_average(ie, mask)\n",
    "\n",
    "    return ie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ie_mid_to_attn_features(layer, grad, mask):\n",
    "    sae = get_nev_it_sae_suite(layer=layer, label=\"attn_out\")\n",
    "    resid_mid = resids_mid[layer]\n",
    "    resid_pre = resids_pre[layer]\n",
    "\n",
    "    ie = sfc_simple(grad, resid_mid - resid_pre, resid_mid - resid_pre, sae)[0]\n",
    "    ie = mask_average(ie, mask)\n",
    "    return ie\n",
    "\n",
    "def ie_mid_to_attn_error(layer, grad, mask):\n",
    "    sae = get_nev_it_sae_suite(layer=layer, label=\"attn_out\")\n",
    "    resid_mid = resids_mid[layer]\n",
    "    resid_pre = resids_pre[layer]\n",
    "\n",
    "    ie = sfc_simple(grad, resid_mid - resid_pre, resid_mid - resid_pre, sae)[1]\n",
    "    ie = mask_average(ie, mask)\n",
    "    return ie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ie_pre_to_pre_features(layer, grad, mask):\n",
    "    sae = get_nev_it_sae_suite(layer=layer)\n",
    "    resid = resids_pre[layer]\n",
    "    ie = sfc_simple(grad, resid, resid, sae)[0]\n",
    "    ie = mask_average(ie, mask)\n",
    "    return ie\n",
    "\n",
    "def ie_pre_to_pre_error(layer, grad, mask):\n",
    "    sae = get_nev_it_sae_suite(layer=layer)\n",
    "    resid = resids_pre[layer]\n",
    "    ie = sfc_simple(grad, resid, resid, sae)[1]\n",
    "    ie = mask_average(ie, mask)\n",
    "    return ie\n",
    "# float((ie_pre_to_pre_features(6, grad_pre[6], \"arrow\") - mask_average(ie_error_resid[6], \"arrow\")).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"output_a6beb9ef365d443cb9e57a16e8394b30\"><script> /* penzai.treescope rendering of a Python object (compressed) */ (()=>{ let observer; let lastStep = new Promise((resolve, reject) => { observer = new IntersectionObserver((entries) => { for (const entry of entries) { if (entry.isIntersecting) { resolve(); observer.disconnect(); return; } } }, {rootMargin: \"1000px\"}); }); window.treescope_decompress_enqueue = (encoded, destId) => { const previous = lastStep; const destElt = document.getElementById(destId); lastStep = (async () => { await previous; let blob = new Blob([ Uint8Array.from(atob(encoded), (m) => m.codePointAt(0)) ]); let reader = blob.stream().pipeThrough( new DecompressionStream(\"deflate\") ).pipeThrough( new TextDecoderStream(\"utf-8\") ).getReader(); let parts = []; while (true) { let step = await reader.read(); if (step.done) { break; } parts.push(step.value); } let newElt = document.createElement(\"div\"); newElt.innerHTML = parts.join(\"\"); destElt.parentNode.replaceChild(newElt, destElt); for (let oldScript of newElt.querySelectorAll(\"script\")) { let newScript = document.createElement(\"script\"); newScript.type = oldScript.type; newScript.textContent = oldScript.textContent; oldScript.parentNode.replaceChild(newScript, oldScript); } })(); requestAnimationFrame(() => { observer.observe(destElt); }); } })(); </script><div id=\"compress_html_1ddc43605fb04390a3dcedf6e193cb24\"><script>window.treescope_decompress_enqueue(\"eNrFV0tv4zYQ/iuzKpCVg1hJnFdXsg0E2xY9LHrZAj20hUBLI4s1TaoklcRd+L93SMm2bMu7Kbpo44PE4Ty+eStjY1cCp5HViCZTFaZaKQufoFKGW65kDBoFs/wJEyiUtMOCLblYxbBUUpmKZUR/LrnFoT/EUGmiCG7s0Kse2lVFVKkkkWcsW8y1qmU+zJRQOm5EE2hPM0EMpI/ntoyh4JbYpEVpE1gyPedyKLCwMYyy0tmQOCyRz0uiXEd3CazHl407Y5NpXtkp8ALCZy5z9bzzECaTCRAELEhBPiBfjzng0zo5IkdphTLncv6YucgYYvv19y+y/chkLpxKWQvRwz1Hmx5EfwLhJuipVQOYTAnk5Tl8UGpBSdBgSwTPKVWOEZxfgkALrWxH1KeGjIfN3ZsJ5CqrlxTQaKbyFZydwRt3E2WCGfOBkha5gDMuTRjsgwoG4EK1seGEKqZJ0/cClz5Da7Jsay39JR17fNW1/KiUdA4+K71oPSOTxhKyX4jkrvbIlmeOWKEmx5dMZhhJ9RwOtq4d3cCwERrDzchB7quBw1RGAuXcllQacNVXEZ/PaeO3iwAKgzvoZS0d9i8aNyUvrHPJS7iXNf1eiyHccGr8s0ZjHyVfMsfxg2ZLDJu4Dgb9GTmEUtWmbHKTvCZwGxCTJhT/JHSvh90LHCVJ1fgdFqg15j/jsqKyR3NcQJVwxG3hk5hefUSBmVX6UQgq9Fa2OwRrmRqq1GCQ+IYLXX+RJlCFV+gcpWenbzQu1RPudU1Hx6lOCDdYnf5Cq7/QNYfX3Ay+fbhh0Aw2p9JJ0KnrWqaR3GgbsstLb5Gbw8TcGPGnlo4v9n1jrHO9IyYeTtPrP7lxo5GileF7ar88JA0XjsHl6WSurJrPRTNGUj/9LQHzU44oKOwF4BNpb0Phys6fowWuXEcGOtiMHmLuxLzRGwZbnemSAAYbHGugfdAsgnHOn8ALTg7nGlg2I8D4MgmuAlCSjBJ62eHrxx/akpsN8oBWTrNI87YgUx+kUokcta9Fv+C+YQ/u165SLxIDt0zwjPBGBbGzGZlyc/3EEl7DPlvaoCPunBsyutos20NGmIJgMxRxPEOqaeygyvxf0muv2bjDa7dy28V8lexscen38Ewot7lP2iypOfSx5ZzphUE2p1DLY+lYKhsekEpmwqnXOe2Ng5eJsxKzBS33AZwPdhicaL/Qhn8PoS//GN7+NrqbZW//T3j7QidB3v8HIF0eneFaG5fASnFCoHvscvP1zPpW8IaGvt/MqRr/OlZ37rk5eGwl4iYtuDY2VTJ15d/TWp9rpWh057qpN1Xwr+E3GT+E6Lza+4b2Dd35Yq6YBJ5Pgu0Au7m9x/v8XXGf5Xe3V3cj9m70wK7YNcuygt5vg1aoHav7fX9onpgbJ8ZcVjXtUto/k8DDnqmXoFdJ6yFdNt5Nx5demJ6trq79vsEbTM+ETf5gL9Gj1mwFhVDM3ozCm9HD/bcXA4iiCM7mNqEokKbp4YOWxvZfiVd/gISD7db5G9awwm4=\", \"compress_html_1ddc43605fb04390a3dcedf6e193cb24\");</script><span style=\"color: #aaaaaa; font-family: monospace\">(Loading...)</span></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"compress_html_544127cacadd4c2081f19fe2a3621bed\"><script>window.treescope_decompress_enqueue(\"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\", \"compress_html_544127cacadd4c2081f19fe2a3621bed\");</script></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"output_dest_a6beb9ef365d443cb9e57a16e8394b30\"><script> (()=>{ const output = document.getElementById(\"output_a6beb9ef365d443cb9e57a16e8394b30\"); const dest = document.getElementById(\"output_dest_a6beb9ef365d443cb9e57a16e8394b30\"); dest.parentNode.replaceChild(output, dest); })(); </script></div>"
      ],
      "text/plain": [
       "# jax.Array float32(32768,) ≈-1.3e-08 ±2.6e-05 [≥-0.0023, ≤0.0023] zero:32_682 nonzero:86\n",
       "  Array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ie_pre_to_pre_features(6, grad_pre[6], \"prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_through_transcoder(layer, grad):\n",
    "    sae = get_nev_it_sae_suite(layer, label=\"transcoder\")\n",
    "    resid_mid = resids_mid[layer]\n",
    "\n",
    "    def f(resid_mid):\n",
    "        resid_mid = mlp_normalize(layer, resid_mid)\n",
    "        # we ignore error nodes\n",
    "        weights = resids_to_weights(resid_mid, sae)\n",
    "        recon = weights_to_resid(weights, sae)\n",
    "\n",
    "        return recon\n",
    "\n",
    "    grad = jax.vjp(f, resid_mid)[1](grad,)[0]\n",
    "\n",
    "    return grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_through_mlp(layer, grad):\n",
    "    mlp = llama.select().at_instances_of(LlamaBlock).pick_nth_selected(layer).at_instances_of(pz.nn.Residual).pick_nth_selected(1).get().delta\n",
    "    resid_mid = resids_mid[layer]\n",
    "    def f(resid_mid):\n",
    "        resids_mid = pz.nx.wrap(resid_mid, \"batch\", \"seq\", \"embedding\")\n",
    "        out = mlp(resids_mid)\n",
    "        return out.unwrap(\"batch\", \"seq\", \"embedding\").astype(resid_mid.dtype)\n",
    "    return jax.vjp(f, resid_mid)[1](grad.astype(resid_mid.dtype),)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_through_attn(layer, grad):\n",
    "    subblock = llama.select().at_instances_of(LlamaBlock).pick_nth_selected(layer).at_instances_of(pz.nn.Residual).pick_nth_selected(0).get().delta\n",
    "\n",
    "    si_selection = subblock.select().at_instances_of(pz.de.HandledSideInputRef)\n",
    "    keys = sorted(set([ref.tag for ref in si_selection.get_sequence()]))\n",
    "    replaced = si_selection.apply(lambda ref: pz.de.SideInputRequest(tag=ref.tag))\n",
    "    subblock = pz.de.WithSideInputsFromInputTuple.handling(replaced, keys)\n",
    "\n",
    "    side_inputs = {\n",
    "        'positions': llama_inputs.positions,\n",
    "        'attn_mask': llama_inputs.attention_mask\n",
    "    }\n",
    "\n",
    "    def f(resid):\n",
    "        resid_pre = pz.nx.wrap(resid, \"batch\", \"seq\", \"embedding\")\n",
    "        attn_out = subblock((resid_pre,) + tuple(side_inputs[tag] for tag in subblock.side_input_tags))\n",
    "\n",
    "        attn_out = attn_out.unwrap(\"batch\", \"seq\", \"embedding\") \n",
    "\n",
    "        return attn_out.astype(resid.dtype)\n",
    "\n",
    "    resid = resids_pre[layer]\n",
    "    return jax.vjp(f, resid)[1](grad.astype(resid.dtype),)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ies = ie_resid[12]\n",
    "ies = mask_average(ies, \"arrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"output_b1158c6a1cfa4413aff5816a9cf4fd89\"><script> /* penzai.treescope rendering of a Python object (compressed) */ (()=>{ let observer; let lastStep = new Promise((resolve, reject) => { observer = new IntersectionObserver((entries) => { for (const entry of entries) { if (entry.isIntersecting) { resolve(); observer.disconnect(); return; } } }, {rootMargin: \"1000px\"}); }); window.treescope_decompress_enqueue = (encoded, destId) => { const previous = lastStep; const destElt = document.getElementById(destId); lastStep = (async () => { await previous; let blob = new Blob([ Uint8Array.from(atob(encoded), (m) => m.codePointAt(0)) ]); let reader = blob.stream().pipeThrough( new DecompressionStream(\"deflate\") ).pipeThrough( new TextDecoderStream(\"utf-8\") ).getReader(); let parts = []; while (true) { let step = await reader.read(); if (step.done) { break; } parts.push(step.value); } let newElt = document.createElement(\"div\"); newElt.innerHTML = parts.join(\"\"); destElt.parentNode.replaceChild(newElt, destElt); for (let oldScript of newElt.querySelectorAll(\"script\")) { let newScript = document.createElement(\"script\"); newScript.type = oldScript.type; newScript.textContent = oldScript.textContent; oldScript.parentNode.replaceChild(newScript, oldScript); } })(); requestAnimationFrame(() => { observer.observe(destElt); }); } })(); </script><div id=\"compress_html_3f457d453b344e71a41e69eb917d9d2d\"><script>window.treescope_decompress_enqueue(\"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\", \"compress_html_3f457d453b344e71a41e69eb917d9d2d\");</script><span style=\"color: #aaaaaa; font-family: monospace\">(Loading...)</span></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"compress_html_24cfe153b2d54e7387ae2220acd983da\"><script>window.treescope_decompress_enqueue(\"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\", \"compress_html_24cfe153b2d54e7387ae2220acd983da\");</script></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"output_dest_b1158c6a1cfa4413aff5816a9cf4fd89\"><script> (()=>{ const output = document.getElementById(\"output_b1158c6a1cfa4413aff5816a9cf4fd89\"); const dest = document.getElementById(\"output_dest_b1158c6a1cfa4413aff5816a9cf4fd89\"); dest.parentNode.replaceChild(output, dest); })(); </script></div>"
      ],
      "text/plain": [
       "[# jax.Array float32(30,) ≈0.0012 ±0.0012 [≥0.0003, ≤0.0052] nonzero:30\n",
       "   Array([0.00515363, 0.00363038, 0.00307088, 0.00272385, 0.00263665,\n",
       "          0.00251921, 0.00248203, 0.00158354, 0.00141052, 0.00093801,\n",
       "          0.00084221, 0.000733  , 0.00071481, 0.00070495, 0.0006948 ,\n",
       "          0.00065009, 0.00064819, 0.00064437, 0.00058913, 0.00056076,\n",
       "          0.00055267, 0.00053456, 0.00050256, 0.00044708, 0.00040716,\n",
       "          0.00033888, 0.00031714, 0.00030809, 0.00030625, 0.00030374],      dtype=float32)\n",
       " ,\n",
       " # jax.Array int32(30,) [≥507, ≤32_734] nonzero:30\n",
       "   Array([ 9157,  1112, 23723, 13869, 16983, 11386, 14154, 28260, 14214,\n",
       "          11958, 19580, 10812, 23598,  3310, 19827,   507,  7525, 21048,\n",
       "          16736, 20601, 24603, 14220,  6282, 23657, 23808, 22231, 21623,\n",
       "          15223, 11506, 32734], dtype=int32)\n",
       " ]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.lax.top_k(ies, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.19it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "\n",
    "layer = 12\n",
    "feature_idx = 9157\n",
    "mask = \"arrow\"\n",
    "\n",
    "resid_grad = pre_feature_to_pre(layer, feature_idx, mask)\n",
    "feature_effects = {}\n",
    "for layer in trange(layer - 1, 5, -1):\n",
    "    for mask in masks:\n",
    "        feature_effects[(\"t\", layer, mask)] = ie_pre_to_transcoder_features(layer, resid_grad, mask)\n",
    "        feature_effects[(\"et\", layer, mask)] = ie_pre_to_transcoder_error(layer, resid_grad, mask)\n",
    "    # # does not work # resid_grad = resid_grad - grad_through_mlp(layer, resid_grad)\n",
    "    # resid_grad = resid_grad + grad_through_mlp(layer, resid_grad)\n",
    "    for mask in masks:\n",
    "        feature_effects[(\"a\", layer, mask)] = ie_mid_to_attn_features(layer, resid_grad, mask)\n",
    "        feature_effects[(\"ea\", layer, mask)] = ie_mid_to_attn_error(layer, resid_grad, mask)\n",
    "    # # does not work # resid_grad = resid_grad - grad_through_attn(layer, resid_grad)\n",
    "    # resid_grad = resid_grad + grad_through_attn(layer, resid_grad)\n",
    "    for mask in masks:\n",
    "        feature_effects[(\"r\", layer, mask)] = ie_pre_to_pre_features(layer, resid_grad, mask)\n",
    "        feature_effects[(\"er\", layer, mask)] = ie_pre_to_pre_error(layer, resid_grad, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/180 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 180/180 [00:03<00:00, 53.87it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "top_effects = []\n",
    "k = 32\n",
    "abs_effects = False\n",
    "for key, features in tqdm(feature_effects.items()):\n",
    "    if features.ndim == 0:\n",
    "        top_effects.append((float(features), key, 0))\n",
    "        continue\n",
    "    effects, indices = jax.lax.top_k(features if not abs_effects else jnp.abs(features), k)\n",
    "    for i, e in zip(indices.tolist(), effects.tolist()):\n",
    "        top_effects.append((e, key, i))\n",
    "top_effects.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"output_a70b7c62ae4049c9a2707c607eb4af13\"><script> /* penzai.treescope rendering of a Python object (compressed) */ (()=>{ let observer; let lastStep = new Promise((resolve, reject) => { observer = new IntersectionObserver((entries) => { for (const entry of entries) { if (entry.isIntersecting) { resolve(); observer.disconnect(); return; } } }, {rootMargin: \"1000px\"}); }); window.treescope_decompress_enqueue = (encoded, destId) => { const previous = lastStep; const destElt = document.getElementById(destId); lastStep = (async () => { await previous; let blob = new Blob([ Uint8Array.from(atob(encoded), (m) => m.codePointAt(0)) ]); let reader = blob.stream().pipeThrough( new DecompressionStream(\"deflate\") ).pipeThrough( new TextDecoderStream(\"utf-8\") ).getReader(); let parts = []; while (true) { let step = await reader.read(); if (step.done) { break; } parts.push(step.value); } let newElt = document.createElement(\"div\"); newElt.innerHTML = parts.join(\"\"); destElt.parentNode.replaceChild(newElt, destElt); for (let oldScript of newElt.querySelectorAll(\"script\")) { let newScript = document.createElement(\"script\"); newScript.type = oldScript.type; newScript.textContent = oldScript.textContent; oldScript.parentNode.replaceChild(newScript, oldScript); } })(); requestAnimationFrame(() => { observer.observe(destElt); }); } })(); </script><div id=\"compress_html_d58433ae4a344c189409384e6123f163\"><script>window.treescope_decompress_enqueue(\"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\", \"compress_html_d58433ae4a344c189409384e6123f163\");</script><span style=\"color: #aaaaaa; font-family: monospace\">(Loading...)</span></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"output_dest_a70b7c62ae4049c9a2707c607eb4af13\"><script> (()=>{ const output = document.getElementById(\"output_a70b7c62ae4049c9a2707c607eb4af13\"); const dest = document.getElementById(\"output_dest_a70b7c62ae4049c9a2707c607eb4af13\"); dest.parentNode.replaceChild(output, dest); })(); </script></div>"
      ],
      "text/plain": [
       "[(3.825262683676556e-05, ('er', 10, 'arrow'), 0),\n",
       " (3.696179192047566e-05, ('er', 9, 'arrow'), 0),\n",
       " (3.6785961128771305e-05, ('er', 11, 'arrow'), 0),\n",
       " (3.483711407170631e-05, ('er', 8, 'arrow'), 0),\n",
       " (3.0039775083423592e-05, ('er', 7, 'arrow'), 0),\n",
       " (2.6046691345982254e-05, ('er', 6, 'arrow'), 0),\n",
       " (1.864851583377458e-05, ('ea', 9, 'arrow'), 0),\n",
       " (1.303459248447325e-05, ('ea', 6, 'arrow'), 0),\n",
       " (1.0022412425314542e-05, ('t', 11, 'arrow'), 11868),\n",
       " (5.725710252590943e-06, ('r', 11, 'arrow'), 20013),\n",
       " (5.312870598572772e-06, ('ea', 7, 'arrow'), 0),\n",
       " (5.241968210611958e-06, ('r', 7, 'arrow'), 6814),\n",
       " (4.156298928137403e-06, ('et', 8, 'arrow'), 0),\n",
       " (3.868626208713977e-06, ('t', 11, 'arrow'), 7583),\n",
       " (3.6351477774587693e-06, ('r', 8, 'arrow'), 6063),\n",
       " (3.332952928758459e-06, ('r', 9, 'arrow'), 16780),\n",
       " (2.9112695756339235e-06, ('r', 9, 'arrow'), 19243),\n",
       " (2.852165607691859e-06, ('r', 7, 'arrow'), 16810),\n",
       " (2.563620455475757e-06, ('et', 10, 'arrow'), 0),\n",
       " (2.54974816016329e-06, ('r', 8, 'arrow'), 18678),\n",
       " (2.323580702068284e-06, ('r', 11, 'arrow'), 28800),\n",
       " (2.101049176417291e-06, ('r', 10, 'arrow'), 15973),\n",
       " (1.9500989765219856e-06, ('r', 7, 'arrow'), 9432),\n",
       " (1.9355418316990836e-06, ('r', 6, 'arrow'), 21082),\n",
       " (1.923181116580963e-06, ('r', 11, 'arrow'), 24640),\n",
       " (1.8755390556179918e-06, ('r', 10, 'arrow'), 8426),\n",
       " (1.8105280332747498e-06, ('r', 11, 'arrow'), 3184),\n",
       " (1.810401727198041e-06, ('r', 10, 'arrow'), 24460),\n",
       " (1.7926603277373943e-06, ('t', 10, 'arrow'), 17854),\n",
       " (1.775706095941132e-06, ('a', 11, 'arrow'), 30066),\n",
       " (1.7411440467185457e-06, ('r', 8, 'arrow'), 8442),\n",
       " (1.7342554201604798e-06, ('r', 6, 'arrow'), 2369)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_effects[:k]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micrlhf-progress-_SD4q1c9-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
